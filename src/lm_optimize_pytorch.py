import os
import sys
import numpy as np
import torch
import csv

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥toolsæ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)
# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥åŒç›®å½•ä¸‹çš„æ¨¡å—
sys.path.append(current_dir)

from tools.data_loader import (
    load_joint_angles, get_initial_params, get_error_weights,
    get_fixed_indices, get_parameter_groups, get_optimizable_indices,
    get_laser_tool_matrix,
    get_alternate_optimization_config, get_damping_config, 
    get_convergence_config, get_constraints_config,
    get_output_config, get_max_theta_change_radians
)
from jacobian_torch import (
    compute_error_vector_jacobian, 
    forward_kinematics_T, 
    quaternion_to_rotation_matrix
)

#! å°†æ—‹è½¬çŸ©é˜µè½¬æ¢ä¸ºå››å…ƒæ•°
def _rotation_matrix_to_quaternion(R_matrix):
    """ 
    æ—‹è½¬çŸ©é˜µè½¬æ¢ä¸ºå››å…ƒæ•°å…¬å¼ï¼š
        R = [rx, ry, rz]
        q = [qx, qy, qz, qw]
        qx = (R[2,1] - R[1,2]) / S
        qy = (R[0,2] - R[2,0]) / S
        qz = (R[1,0] - R[0,1]) / S
        qw = (R[0,0] + R[1,1] + R[2,2] + 1) / 4
    """
    if not torch.is_tensor(R_matrix):
        R_matrix = torch.as_tensor(R_matrix, dtype=torch.float64)
    q = torch.zeros(4, dtype=R_matrix.dtype, device=R_matrix.device)
    trace = R_matrix[0,0] + R_matrix[1,1] + R_matrix[2,2]   
    if trace > 1e-8: 
        S = torch.sqrt(trace + 1.0) * 2.0 
        q[3] = 0.25 * S  
        q[0] = (R_matrix[2,1] - R_matrix[1,2]) / S 
        q[1] = (R_matrix[0,2] - R_matrix[2,0]) / S 
        q[2] = (R_matrix[1,0] - R_matrix[0,1]) / S 
    elif (R_matrix[0,0] > R_matrix[1,1]) and (R_matrix[0,0] > R_matrix[2,2]):
        S = torch.sqrt(1.0 + R_matrix[0,0] - R_matrix[1,1] - R_matrix[2,2] + 1e-12) * 2.0 
        q[0] = 0.25 * S # qx
        q[1] = (R_matrix[0,1] + R_matrix[1,0]) / S 
        q[2] = (R_matrix[0,2] + R_matrix[2,0]) / S 
    elif R_matrix[1,1] > R_matrix[2,2]:
        S = torch.sqrt(1.0 + R_matrix[1,1] - R_matrix[0,0] - R_matrix[2,2] + 1e-12) * 2.0 
        q[3] = (R_matrix[0,2] - R_matrix[2,0]) / S 
        q[0] = (R_matrix[0,1] + R_matrix[1,0]) / S 
        q[1] = 0.25 * S 
        q[2] = (R_matrix[1,2] + R_matrix[2,1]) / S 
    else:
        S = torch.sqrt(1.0 + R_matrix[2,2] - R_matrix[0,0] - R_matrix[1,1] + 1e-12) * 2.0 
        q[3] = (R_matrix[1,0] - R_matrix[0,1]) / S 
        q[0] = (R_matrix[0,2] + R_matrix[2,0]) / S 
        q[1] = (R_matrix[1,2] + R_matrix[2,1]) / S 
        q[2] = 0.25 * S 

    #* å½’ä¸€åŒ–å››å…ƒæ•°
    norm_q = torch.linalg.norm(q)
    if norm_q > 1e-9: 
        q = q / norm_q
    else: 
        q = torch.tensor([0.0, 0.0, 0.0, 1.0], dtype=R_matrix.dtype, device=R_matrix.device)
    return q 

#! å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ¬§æ‹‰è§’ (ZYXé¡ºåº: yaw, pitch, roll)
def _quaternion_to_euler_angles(q):
    """ 
    å››å…ƒæ•°è½¬æ¢ä¸ºæ¬§æ‹‰è§’å…¬å¼ï¼š
        q = [qx, qy, qz, qw]
        roll = atan2(sinr_cosp, cosr_cosp)
        pitch = asin(sinp)
        yaw = atan2(siny_cosp, cosy_cosp)
    """
    qx, qy, qz, qw = q[0], q[1], q[2], q[3]

 
    sinr_cosp = 2 * (qw * qx + qy * qz)
    cosr_cosp = 1 - 2 * (qx * qx + qy * qy)
    roll = torch.atan2(sinr_cosp, cosr_cosp)

    sinp = 2 * (qw * qy - qz * qx)
    if torch.abs(sinp) >= 1:
        pitch = torch.copysign(torch.pi / 2, sinp) 
    else:
        pitch = torch.asin(sinp)

   
    siny_cosp = 2 * (qw * qz + qx * qy)
    cosy_cosp = 1 - 2 * (qy * qy + qz * qz)
    yaw = torch.atan2(siny_cosp, cosy_cosp)

    return torch.stack([yaw, pitch, roll])

#! è®¡ç®—å•ç»„æ•°æ®çš„è¯¯å·®å‘é‡ï¼ˆåŠ æƒé‡ï¼‰
def compute_error_vector(params, joint_angles, laser_matrix, weights=None):
    # å¦‚æœæ²¡æœ‰æä¾›æƒé‡ï¼Œä»é…ç½®è·å–
    if weights is None:
        weights = get_error_weights()
        
    #* è·å–å…³èŠ‚è§’åº¦å’Œå‚æ•°
    q_t = torch.as_tensor(joint_angles, dtype=torch.float64)
    params_t = torch.as_tensor(params, dtype=torch.float64) 

    #* æå–å‚æ•°
    params_for_fk = params_t[0:31] 
    t_laser_base_pos = params_t[31:34]
    t_laser_base_quat = params_t[34:38] 

  
    T_pred_robot_base, _ = forward_kinematics_T(q_t, params_for_fk) 

    #* æ„å»ºT_laser_baseå˜æ¢çŸ©é˜µï¼ˆåŸºåº§åœ¨æ¿€å…‰åæ ‡ç³»ä¸‹çš„ä½å§¿ï¼‰
    R_laser_base = quaternion_to_rotation_matrix(t_laser_base_quat) 
    T_laser_base_matrix = torch.eye(4, dtype=torch.float64)
    T_laser_base_matrix[0:3, 0:3] = R_laser_base
    T_laser_base_matrix[0:3, 3] = t_laser_base_pos
    
    #* å°†æœºå™¨äººé¢„æµ‹ä½å§¿è½¬æ¢åˆ°æ¿€å…‰è·Ÿè¸ªä»ªåæ ‡ç³»
    T_pred_in_laser_frame = torch.matmul(T_laser_base_matrix, T_pred_robot_base)
    
    #* è®¡ç®—æ¿€å…‰è·Ÿè¸ªä»ª-åŸºåº§å˜æ¢çŸ©é˜µ
    pred_pos = T_pred_in_laser_frame[0:3, 3]
    pred_R = T_pred_in_laser_frame[0:3, 0:3]

    #* æå–æµ‹é‡ä½ç½®å’Œæ—‹è½¬çŸ©é˜µ
    T_laser_t = torch.as_tensor(laser_matrix, dtype=torch.float64)
    meas_pos = T_laser_t[0:3, 3]
    meas_R = T_laser_t[0:3, 0:3]

    #* ä½ç½®è¯¯å·®
    pos_error = pred_pos - meas_pos

    #* å°†æ—‹è½¬çŸ©é˜µè½¬æ¢ä¸ºå››å…ƒæ•° [qx, qy, qz, qw]
    q_pred = _rotation_matrix_to_quaternion(pred_R) 
    q_meas = _rotation_matrix_to_quaternion(meas_R) 

    #* è®¡ç®—å››å…ƒæ•°å…±è½­
    q_meas_conj_x = -q_meas[0]
    q_meas_conj_y = -q_meas[1]
    q_meas_conj_z = -q_meas[2]
    q_meas_conj_w =  q_meas[3]
    
    # å››å…ƒæ•°ä¹˜æ³•: q_pred * q_meas_conj
    # q_pred = [x1, y1, z1, w1], q_meas_conj = [x2, y2, z2, w2]
    # qw = w1*w2 - x1*x2 - y1*y2 - z1*z2
    # qx = w1*x2 + x1*w2 + y1*z2 - z1*y2
    # qy = w1*y2 - x1*z2 + y1*w2 + z1*x2
    # qz = w1*z2 + x1*y2 - y1*x2 + z1*w2
    #* è®¡ç®—é¢„æµ‹å’Œå®é™…ä¹‹é—´çš„è¯¯å·®æ—‹è½¬
    q_err_w = q_pred[3] * q_meas_conj_w - q_pred[0] * q_meas_conj_x - q_pred[1] * q_meas_conj_y - q_pred[2] * q_meas_conj_z
    q_err_x = q_pred[3] * q_meas_conj_x + q_pred[0] * q_meas_conj_w + q_pred[1] * q_meas_conj_z - q_pred[2] * q_meas_conj_y
    q_err_y = q_pred[3] * q_meas_conj_y - q_pred[0] * q_meas_conj_z + q_pred[1] * q_meas_conj_w + q_pred[2] * q_meas_conj_x
    q_err_z = q_pred[3] * q_meas_conj_z + q_pred[0] * q_meas_conj_y - q_pred[1] * q_meas_conj_x + q_pred[2] * q_meas_conj_w

    #* å°†è¯¯å·®å››å…ƒæ•°è½¬æ¢ä¸ºæ¬§æ‹‰è§’è¯¯å·® [yaw, pitch, roll]
    error_quaternion = torch.stack([q_err_x, q_err_y, q_err_z, q_err_w])
    # å½’ä¸€åŒ–è¯¯å·®å››å…ƒæ•°
    norm_error_q = torch.linalg.norm(error_quaternion)
    if norm_error_q > 1e-9:
        error_quaternion_normalized = error_quaternion / norm_error_q
    else:
        # å¦‚æœæ¨¡é•¿æ¥è¿‘äºé›¶ï¼Œè¯´æ˜æ—‹è½¬å¾ˆå°ï¼Œæˆ–è€…q_predå’Œq_measéå¸¸æ¥è¿‘ï¼Œæ¬§æ‹‰è§’è¯¯å·®ä¹Ÿæ¥è¿‘äºé›¶
        error_quaternion_normalized = torch.tensor([0.0, 0.0, 0.0, 1.0], dtype=params.dtype, device=params.device)

    orient_error = _quaternion_to_euler_angles(error_quaternion_normalized) # ä½¿ç”¨æ¬§æ‹‰è§’ä½œä¸ºæ–¹å‘è¯¯å·®
    
    combined_error = torch.cat((pos_error, orient_error))
    return combined_error * torch.as_tensor(weights, dtype=torch.float64)



#! è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„å‡æ–¹æ ¹è¯¯å·®
def compute_total_error_avg(params, joint_angles, laser_matrices, weights=None):
    # å¦‚æœæ²¡æœ‰æä¾›æƒé‡ï¼Œä»é…ç½®è·å–
    if weights is None:
        weights = get_error_weights()
        
    total_error_sum_sq = 0.0 
    n_samples = len(joint_angles)
    if n_samples == 0:
        return torch.tensor(0.0, dtype=torch.float64) 

    for i in range(n_samples):
        error_vec = compute_error_vector(params, joint_angles[i], laser_matrices[i], weights) 
        total_error_sum_sq += torch.sum(error_vec**2)
    
    #* è¿”å›å‡æ–¹æ ¹è¯¯å·® (RMSEè¯¯å·®) å…¬å¼ï¼šRMSE = sqrt(sum(error_vec^2) / n_samples)
    mean_squared_error = total_error_sum_sq / n_samples
    return torch.sqrt(mean_squared_error)

#! ç”Ÿæˆä¼˜åŒ–å‰åè¯¦ç»†å¯¹æ¯”åˆ†æ
def generate_detailed_comparison(initial_params, optimized_params):
    """
    ç”Ÿæˆä¼˜åŒ–å‰åçš„è¯¦ç»†å¯¹æ¯”åˆ†ææ•°æ®
    
    å‚æ•°:
    initial_params: åˆå§‹å‚æ•°
    optimized_params: ä¼˜åŒ–åçš„å‚æ•°
    
    è¿”å›:
    pandas.DataFrame: åŒ…å«è¯¦ç»†å¯¹æ¯”æ•°æ®çš„DataFrame
    """
    from tools.data_loader import load_joint_angles, get_laser_tool_matrix
    import pandas as pd
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    joint_angles = load_joint_angles()
    laser_matrices = get_laser_tool_matrix()
    n_samples = len(joint_angles)
    
    print(f"   ğŸ“Š åˆ†æ {n_samples} ç»„æµ‹è¯•æ•°æ®çš„ä¼˜åŒ–æ•ˆæœ...")
    
    # è®¡ç®—æƒé‡
    weights = get_error_weights()
    
    comparison_data = []
    
    for i in range(n_samples):
        joint_angle = joint_angles[i]
        laser_matrix = laser_matrices[i]
        
        # è®¡ç®—ä¼˜åŒ–å‰çš„è¯¯å·®
        error_before = compute_error_vector(initial_params, joint_angle, laser_matrix, weights)
        pos_error_before = error_before[:3].detach().numpy()
        orient_error_before = error_before[3:].detach().numpy()
        total_error_before = torch.norm(error_before).item()
        
        # è®¡ç®—ä¼˜åŒ–å‰çš„åˆ†è§£è¯¯å·®ï¼ˆä½ç½®è¯¯å·®å’Œå§¿æ€è¯¯å·®ï¼‰
        pos_error_magnitude_before = np.sqrt(np.sum(pos_error_before**2))
        orient_error_magnitude_before = np.sqrt(np.sum(orient_error_before**2))
        
        # è®¡ç®—ä¼˜åŒ–åçš„è¯¯å·®
        error_after = compute_error_vector(optimized_params, joint_angle, laser_matrix, weights)
        pos_error_after = error_after[:3].detach().numpy()
        orient_error_after = error_after[3:].detach().numpy()
        total_error_after = torch.norm(error_after).item()
        
        # è®¡ç®—ä¼˜åŒ–åçš„åˆ†è§£è¯¯å·®ï¼ˆä½ç½®è¯¯å·®å’Œå§¿æ€è¯¯å·®ï¼‰
        pos_error_magnitude_after = np.sqrt(np.sum(pos_error_after**2))
        orient_error_magnitude_after = np.sqrt(np.sum(orient_error_after**2))
        
        # è®¡ç®—æ”¹è¿›ç‡
        improvement_rate = ((total_error_before - total_error_after) / total_error_before) * 100 if total_error_before > 0 else 0
        pos_improvement_rate = ((pos_error_magnitude_before - pos_error_magnitude_after) / pos_error_magnitude_before) * 100 if pos_error_magnitude_before > 0 else 0
        orient_improvement_rate = ((orient_error_magnitude_before - orient_error_magnitude_after) / orient_error_magnitude_before) * 100 if orient_error_magnitude_before > 0 else 0
        
        # æ·»åŠ åˆ°å¯¹æ¯”æ•°æ® - æŒ‰ç…§ä¼˜åŒ–å‰åæˆå¯¹çš„é¡ºåºæ’åˆ—
        comparison_data.append({
            'æ•°æ®ç»„': f'ç¬¬{i+1}ç»„',
            'ä¼˜åŒ–å‰Xè¯¯å·®(mm)': f'{pos_error_before[0]:.6f}',
            'ä¼˜åŒ–åXè¯¯å·®(mm)': f'{pos_error_after[0]:.6f}',
            'ä¼˜åŒ–å‰Yè¯¯å·®(mm)': f'{pos_error_before[1]:.6f}',
            'ä¼˜åŒ–åYè¯¯å·®(mm)': f'{pos_error_after[1]:.6f}',
            'ä¼˜åŒ–å‰Zè¯¯å·®(mm)': f'{pos_error_before[2]:.6f}',
            'ä¼˜åŒ–åZè¯¯å·®(mm)': f'{pos_error_after[2]:.6f}',
            'ä¼˜åŒ–å‰Rxè¯¯å·®(åº¦)': f'{orient_error_before[0]:.6f}',
            'ä¼˜åŒ–åRxè¯¯å·®(åº¦)': f'{orient_error_after[0]:.6f}',
            'ä¼˜åŒ–å‰Ryè¯¯å·®(åº¦)': f'{orient_error_before[1]:.6f}',
            'ä¼˜åŒ–åRyè¯¯å·®(åº¦)': f'{orient_error_after[1]:.6f}',
            'ä¼˜åŒ–å‰Rzè¯¯å·®(åº¦)': f'{orient_error_before[2]:.6f}',
            'ä¼˜åŒ–åRzè¯¯å·®(åº¦)': f'{orient_error_after[2]:.6f}',
            'ä¼˜åŒ–å‰ä½ç½®è¯¯å·®(mm)': f'{pos_error_magnitude_before:.6f}',
            'ä¼˜åŒ–åä½ç½®è¯¯å·®(mm)': f'{pos_error_magnitude_after:.6f}',
            'ä¼˜åŒ–å‰å§¿æ€è¯¯å·®(åº¦)': f'{orient_error_magnitude_before:.6f}',
            'ä¼˜åŒ–åå§¿æ€è¯¯å·®(åº¦)': f'{orient_error_magnitude_after:.6f}',
            'ä¼˜åŒ–å‰æ€»è¯¯å·®(L2èŒƒæ•°)': f'{total_error_before:.6f}',
            'ä¼˜åŒ–åæ€»è¯¯å·®(L2èŒƒæ•°)': f'{total_error_after:.6f}',
            'ä½ç½®æ”¹è¿›ç‡(%)': f'{pos_improvement_rate:.2f}%',
            'å§¿æ€æ”¹è¿›ç‡(%)': f'{orient_improvement_rate:.2f}%',
            'æ€»è¯¯å·®æ”¹è¿›ç‡(%)': f'{improvement_rate:.2f}%'
        })
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    total_errors_before = [float(row['ä¼˜åŒ–å‰æ€»è¯¯å·®(L2èŒƒæ•°)']) for row in comparison_data]
    total_errors_after = [float(row['ä¼˜åŒ–åæ€»è¯¯å·®(L2èŒƒæ•°)']) for row in comparison_data]
    pos_errors_before = [float(row['ä¼˜åŒ–å‰ä½ç½®è¯¯å·®(mm)']) for row in comparison_data]
    pos_errors_after = [float(row['ä¼˜åŒ–åä½ç½®è¯¯å·®(mm)']) for row in comparison_data]
    orient_errors_before = [float(row['ä¼˜åŒ–å‰å§¿æ€è¯¯å·®(åº¦)']) for row in comparison_data]
    orient_errors_after = [float(row['ä¼˜åŒ–åå§¿æ€è¯¯å·®(åº¦)']) for row in comparison_data]
    
    avg_error_before = np.mean(total_errors_before)
    avg_error_after = np.mean(total_errors_after)
    avg_pos_error_before = np.mean(pos_errors_before)
    avg_pos_error_after = np.mean(pos_errors_after)
    avg_orient_error_before = np.mean(orient_errors_before)
    avg_orient_error_after = np.mean(orient_errors_after)
    
    overall_improvement = ((avg_error_before - avg_error_after) / avg_error_before) * 100 if avg_error_before > 0 else 0
    pos_overall_improvement = ((avg_pos_error_before - avg_pos_error_after) / avg_pos_error_before) * 100 if avg_pos_error_before > 0 else 0
    orient_overall_improvement = ((avg_orient_error_before - avg_orient_error_after) / avg_orient_error_before) * 100 if avg_orient_error_before > 0 else 0
    
    # æ·»åŠ ç»Ÿè®¡è¡Œ - åŒ¹é…æ–°çš„åˆ—é¡ºåº
    comparison_data.append({
        'æ•°æ®ç»„': 'å¹³å‡å€¼',
        'ä¼˜åŒ–å‰Xè¯¯å·®(mm)': '',
        'ä¼˜åŒ–åXè¯¯å·®(mm)': '',
        'ä¼˜åŒ–å‰Yè¯¯å·®(mm)': '',
        'ä¼˜åŒ–åYè¯¯å·®(mm)': '',
        'ä¼˜åŒ–å‰Zè¯¯å·®(mm)': '',
        'ä¼˜åŒ–åZè¯¯å·®(mm)': '',
        'ä¼˜åŒ–å‰Rxè¯¯å·®(åº¦)': '',
        'ä¼˜åŒ–åRxè¯¯å·®(åº¦)': '',
        'ä¼˜åŒ–å‰Ryè¯¯å·®(åº¦)': '',
        'ä¼˜åŒ–åRyè¯¯å·®(åº¦)': '',
        'ä¼˜åŒ–å‰Rzè¯¯å·®(åº¦)': '',
        'ä¼˜åŒ–åRzè¯¯å·®(åº¦)': '',
        'ä¼˜åŒ–å‰ä½ç½®è¯¯å·®(mm)': f'{avg_pos_error_before:.6f}',
        'ä¼˜åŒ–åä½ç½®è¯¯å·®(mm)': f'{avg_pos_error_after:.6f}',
        'ä¼˜åŒ–å‰å§¿æ€è¯¯å·®(åº¦)': f'{avg_orient_error_before:.6f}',
        'ä¼˜åŒ–åå§¿æ€è¯¯å·®(åº¦)': f'{avg_orient_error_after:.6f}',
        'ä¼˜åŒ–å‰æ€»è¯¯å·®(L2èŒƒæ•°)': f'{avg_error_before:.6f}',
        'ä¼˜åŒ–åæ€»è¯¯å·®(L2èŒƒæ•°)': f'{avg_error_after:.6f}',
        'ä½ç½®æ”¹è¿›ç‡(%)': f'{pos_overall_improvement:.2f}%',
        'å§¿æ€æ”¹è¿›ç‡(%)': f'{orient_overall_improvement:.2f}%',
        'æ€»è¯¯å·®æ”¹è¿›ç‡(%)': f'{overall_improvement:.2f}%'
    })
    
    print(f"   âœ… æ€»ä½“å¹³å‡è¯¯å·®: {avg_error_before:.6f} â†’ {avg_error_after:.6f}")
    print(f"   ğŸ“ ä½ç½®è¯¯å·®: {avg_pos_error_before:.6f} â†’ {avg_pos_error_after:.6f} (æ”¹è¿›ç‡: {pos_overall_improvement:.2f}%)")
    print(f"   ğŸ”„ å§¿æ€è¯¯å·®: {avg_orient_error_before:.6f} â†’ {avg_orient_error_after:.6f} (æ”¹è¿›ç‡: {orient_overall_improvement:.2f}%)")
    print(f"   ğŸ“ˆ æ€»ä½“æ”¹è¿›ç‡: {overall_improvement:.2f}%")
    
    return pd.DataFrame(comparison_data)

#! ä¿å­˜ä¼˜åŒ–åçš„DHå‚æ•°å’ŒTCPå‚æ•°
def save_optimization_results(params, initial_params=None, filepath_prefix=None):
    """
    ä¿å­˜ä¼˜åŒ–ç»“æœï¼Œè·¯å¾„å¯ä»¥ä»é…ç½®æ–‡ä»¶è¯»å–
    
    å‚æ•°:
    params: ä¼˜åŒ–åçš„å‚æ•°
    initial_params: åˆå§‹å‚æ•°ï¼ˆç”¨äºå¯¹æ¯”åˆ†æï¼‰
    filepath_prefix: æ–‡ä»¶è·¯å¾„å‰ç¼€ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    """
    # ä»é…ç½®æ–‡ä»¶è¯»å–é»˜è®¤è·¯å¾„
    if filepath_prefix is None:
        output_config = get_output_config()
        filepath_prefix = output_config.get('results_prefix', 'results/optimized')
    
    dirpath = os.path.dirname(filepath_prefix)
    if dirpath and not os.path.exists(dirpath):
        os.makedirs(dirpath)
    dh_params = params[0:24]
    tcp_params = params[24:31]
    t_laser_base_params = params[31:38]
    dh_filepath = f"{filepath_prefix}_dh_parameters.csv"
    dh_matrix = np.array(dh_params).reshape(6, 4)
    header_dh = "alpha,a,d,theta_offset"
    row_labels_dh = [f"Joint_{i+1}" for i in range(6)]
    with open(dh_filepath, 'w') as f:
        f.write(f",{header_dh}\n")  
        for i, row in enumerate(dh_matrix):
            f.write(f"{row_labels_dh[i]},{row[0]:.6f},{row[1]:.6f},{row[2]:.6f},{row[3]:.6f}\n")
    print(f"ä¼˜åŒ–åçš„DHå‚æ•°å·²ä¿å­˜åˆ°: {dh_filepath}")
    
    # ä¿å­˜TCPå‚æ•°
    tcp_filepath = f"{filepath_prefix}_tcp_parameters.csv"
    header_tcp = "parameter,value"
    tcp_param_names = ["tx", "ty", "tz", "qx", "qy", "qz", "qw"]
    with open(tcp_filepath, 'w') as f:
        f.write(f"{header_tcp}\n")
        for name, value in zip(tcp_param_names, tcp_params):
            f.write(f"{name},{value:.6f}\n")
    print(f"ä¼˜åŒ–åçš„TCPå‚æ•°å·²ä¿å­˜åˆ°: {tcp_filepath}")
    
    # ä¿å­˜æ¿€å…‰è·Ÿè¸ªä»ª-åŸºåº§å˜æ¢å‚æ•°
    t_laser_base_filepath = f"{filepath_prefix}_t_laser_base_parameters.csv"
    header_t_laser_base = "parameter,value"
    t_laser_base_param_names = ["tx", "ty", "tz", "qx", "qy", "qz", "qw"]
    with open(t_laser_base_filepath, 'w') as f:
        f.write(f"{header_t_laser_base}\n")
        for name, value in zip(t_laser_base_param_names, t_laser_base_params):
            f.write(f"{name},{value:.6f}\n")
    print(f"ä¼˜åŒ–åçš„æ¿€å…‰è·Ÿè¸ªä»ª-åŸºåº§å˜æ¢å‚æ•°å·²ä¿å­˜åˆ°: {t_laser_base_filepath}")
    
    # ç”Ÿæˆè¯¦ç»†å¯¹æ¯”åˆ†ææ•°æ®
    detailed_comparison_df = None
    if initial_params is not None:
        print("\nğŸ” ç”Ÿæˆä¼˜åŒ–å‰åè¯¦ç»†å¯¹æ¯”åˆ†æ...")
        detailed_comparison_df = generate_detailed_comparison(initial_params, params)
    
    # è‡ªåŠ¨ç”ŸæˆExcelæ±‡æ€»æ–‡ä»¶
    try:
        import pandas as pd
        from pathlib import Path
        
        # åˆ›å»ºExcelæ±‡æ€»æ–‡ä»¶
        results_dir = Path(dirpath)
        excel_filepath = results_dir / "ä¼˜åŒ–ç»“æœæ±‡æ€».xlsx"
        
        # è¯»å–ä¸‰ä¸ªCSVæ–‡ä»¶çš„æ•°æ®
        dh_df = pd.read_csv(dh_filepath)
        tcp_df = pd.read_csv(tcp_filepath)
        base_df = pd.read_csv(t_laser_base_filepath)
        
        # åˆ›å»ºä¸€ä¸ªç»¼åˆçš„æ•°æ®æ¡†ï¼Œå°†ä¸‰ä¸ªç»“æœåˆå¹¶åˆ°ä¸€ä¸ªå·¥ä½œè¡¨
        with pd.ExcelWriter(excel_filepath, engine='openpyxl') as writer:
            # åˆ›å»ºå·¥ä½œç°¿
            workbook = writer.book
            worksheet = workbook.create_sheet(title="ä¼˜åŒ–ç»“æœæ±‡æ€»")
            
            # è®¾ç½®æ ‡é¢˜æ ·å¼
            from openpyxl.styles import Font, Alignment, PatternFill
            title_font = Font(bold=True, size=14)
            header_font = Font(bold=True, size=12)
            center_alignment = Alignment(horizontal='center', vertical='center')
            header_fill = PatternFill(start_color='E6F3FF', end_color='E6F3FF', fill_type='solid')
            
            # å†™å…¥DHå‚æ•°éƒ¨åˆ†
            row = 1
            worksheet.cell(row=row, column=1, value="ğŸ”§ æœºå™¨äººDHå‚æ•°æ ‡å®šç»“æœ").font = title_font
            worksheet.cell(row=row, column=1).alignment = center_alignment
            worksheet.merge_cells(f'A{row}:E{row}')
            row += 2
            
            # DHå‚æ•°è¡¨å¤´
            dh_headers = ['å…³èŠ‚ç¼–å·', 'Î± (åº¦)', 'a (mm)', 'd (mm)', 'Î¸åç§» (åº¦)']
            for col, header in enumerate(dh_headers, 1):
                cell = worksheet.cell(row=row, column=col, value=header)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
            row += 1
            
            # DHå‚æ•°æ•°æ®
            for i, (_, dh_row) in enumerate(dh_df.iterrows()):
                worksheet.cell(row=row, column=1, value=dh_row.iloc[0])  # å…³èŠ‚åç§°
                for col in range(1, 5):
                    worksheet.cell(row=row, column=col+1, value=f"{dh_row.iloc[col]:.6f}")
                row += 1
            
            # ç©ºè¡Œåˆ†éš”
            row += 2
            
            # å†™å…¥TCPä½å§¿éƒ¨åˆ†
            worksheet.cell(row=row, column=1, value="ğŸ¯ å·¥å…·ä¸­å¿ƒç‚¹(TCP)ä½å§¿").font = title_font
            worksheet.cell(row=row, column=1).alignment = center_alignment
            worksheet.merge_cells(f'A{row}:B{row}')
            row += 2
            
            # TCPä½å§¿è¡¨å¤´å’Œæ•°æ®
            tcp_headers = ['ä½å§¿å‚æ•°', 'ä¼˜åŒ–å€¼']
            for col, header in enumerate(tcp_headers, 1):
                cell = worksheet.cell(row=row, column=col, value=header)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
            row += 1
            
            # TCPå‚æ•°åç§°ç¾åŒ–æ˜ å°„
            tcp_param_names = {
                'tx': 'Xè½´ä½ç§» (mm)',
                'ty': 'Yè½´ä½ç§» (mm)', 
                'tz': 'Zè½´ä½ç§» (mm)',
                'qx': 'å››å…ƒæ•° qx',
                'qy': 'å››å…ƒæ•° qy',
                'qz': 'å››å…ƒæ•° qz',
                'qw': 'å››å…ƒæ•° qw'
            }
            
            for _, tcp_row in tcp_df.iterrows():
                param_name = tcp_param_names.get(tcp_row['parameter'], tcp_row['parameter'])
                worksheet.cell(row=row, column=1, value=param_name)
                worksheet.cell(row=row, column=2, value=f"{tcp_row['value']:.6f}")
                row += 1
            
            # å†™å…¥åŸºåº§ä½å§¿éƒ¨åˆ†ï¼ˆä¸TCPä½å§¿å¹¶æ’æ˜¾ç¤ºï¼‰
            row_start_base = row - len(tcp_df) - 1  # å›åˆ°TCPæ ‡é¢˜è¡Œ
            worksheet.cell(row=row_start_base, column=4, value="ğŸ“ æ¿€å…‰è·Ÿè¸ªä»ªåŸºåº§ä½å§¿").font = title_font
            worksheet.cell(row=row_start_base, column=4).alignment = center_alignment
            worksheet.merge_cells(f'D{row_start_base}:E{row_start_base}')
            row_base = row_start_base + 2
            
            # åŸºåº§ä½å§¿è¡¨å¤´
            base_headers = ['ä½å§¿å‚æ•°', 'ä¼˜åŒ–å€¼']
            for col, header in enumerate(base_headers, 4):
                cell = worksheet.cell(row=row_base, column=col, value=header)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = center_alignment
            row_base += 1
            
            # åŸºåº§å‚æ•°åç§°ç¾åŒ–æ˜ å°„
            base_param_names = {
                'tx': 'Xè½´ä½ç§» (mm)',
                'ty': 'Yè½´ä½ç§» (mm)',
                'tz': 'Zè½´ä½ç§» (mm)', 
                'qx': 'å››å…ƒæ•° qx',
                'qy': 'å››å…ƒæ•° qy',
                'qz': 'å››å…ƒæ•° qz',
                'qw': 'å››å…ƒæ•° qw'
            }
            
            # åŸºåº§ä½å§¿æ•°æ®
            for _, base_row in base_df.iterrows():
                param_name = base_param_names.get(base_row['parameter'], base_row['parameter'])
                worksheet.cell(row=row_base, column=4, value=param_name)
                worksheet.cell(row=row_base, column=5, value=f"{base_row['value']:.6f}")
                row_base += 1
            
            # è°ƒæ•´åˆ—å®½
            worksheet.column_dimensions['A'].width = 18
            worksheet.column_dimensions['B'].width = 15
            worksheet.column_dimensions['C'].width = 15
            worksheet.column_dimensions['D'].width = 20
            worksheet.column_dimensions['E'].width = 15
            
            # åœ¨ä¸»å·¥ä½œè¡¨åº•éƒ¨æ·»åŠ è¯´æ˜
            last_row = worksheet.max_row + 2
            worksheet.cell(row=last_row, column=1, value="ğŸ“‹ è¯´æ˜").font = title_font
            worksheet.cell(row=last_row, column=1).alignment = center_alignment
            
            explanation_lines = [
                "â€¢ DHå‚æ•°ï¼šæœºå™¨äººæ­£å‘è¿åŠ¨å­¦æ ‡å®šå‚æ•°",
                "â€¢ TCPä½å§¿ï¼šå·¥å…·ä¸­å¿ƒç‚¹ç›¸å¯¹æ³•å…°åæ ‡ç³»çš„å˜æ¢",
                "â€¢ åŸºåº§ä½å§¿ï¼šæ¿€å…‰è·Ÿè¸ªä»ªä¸æœºå™¨äººåŸºåº§é—´çš„å˜æ¢å…³ç³»",
                "â€¢ è¯¦ç»†è¯¯å·®åˆ†æè¯·æŸ¥çœ‹'ä¼˜åŒ–å‰åè¯¦ç»†å¯¹æ¯”'å·¥ä½œè¡¨"
            ]
            
            for i, line in enumerate(explanation_lines):
                worksheet.cell(row=last_row + 1 + i, column=1, value=line).font = Font(size=10)
                worksheet.merge_cells(f'A{last_row + 1 + i}:E{last_row + 1 + i}')
            
            # æ·»åŠ è¾¹æ¡†æ ·å¼
            from openpyxl.styles import Border, Side
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'), 
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # ä¸ºæ‰€æœ‰æœ‰æ•°æ®çš„å•å…ƒæ ¼æ·»åŠ è¾¹æ¡†
            for row in worksheet.iter_rows():
                for cell in row:
                    if cell.value is not None:
                        cell.border = thin_border
            
            # æ·»åŠ è¯¦ç»†å¯¹æ¯”åˆ†æå·¥ä½œè¡¨
            if detailed_comparison_df is not None:
                # åˆ›å»ºå¯¹æ¯”åˆ†æå·¥ä½œè¡¨
                comparison_sheet = workbook.create_sheet(title="ä¼˜åŒ–å‰åè¯¦ç»†å¯¹æ¯”")
                
                                # å†™å…¥æ ‡é¢˜
                comparison_sheet.cell(row=1, column=1, value="ğŸ“Š ä¼˜åŒ–å‰åé€ç»„æ•°æ®å¯¹æ¯”åˆ†æ").font = title_font
                comparison_sheet.cell(row=1, column=1).alignment = center_alignment
                comparison_sheet.merge_cells('A1:V1')  # æ‰©å±•åˆå¹¶èŒƒå›´ä»¥é€‚åº”æ–°åˆ—
                
                # æ·»åŠ è®¡ç®—è¯´æ˜
                explanation_text = ("ğŸ’¡ è¯¯å·®è®¡ç®—æ–¹å¼:\n"
                                  "   ä½ç½®è¯¯å·® = âˆš(XÂ²+YÂ²+ZÂ²) (mm)\n"
                                  "   å§¿æ€è¯¯å·® = âˆš(RxÂ²+RyÂ²+RzÂ²) (åº¦)\n" 
                                  "   æ€»è¯¯å·®(L2èŒƒæ•°) = âˆš(XÂ²+YÂ²+ZÂ²+(RxÃ—0.01)Â²+(RyÃ—0.01)Â²+(RzÃ—0.01)Â²)\n"
                                  "   æƒé‡è®¾ç½®: ä½ç½®æƒé‡=1.0, å§¿æ€æƒé‡=0.01")
                comparison_sheet.cell(row=2, column=1, value=explanation_text).font = Font(size=10, italic=True)
                comparison_sheet.cell(row=2, column=1).alignment = Alignment(horizontal='left', vertical='center', wrap_text=True)
                comparison_sheet.merge_cells('A2:V2')  # æ‰©å±•åˆå¹¶èŒƒå›´ä»¥é€‚åº”æ–°åˆ—
                comparison_sheet.row_dimensions[2].height = 40
                
                # å†™å…¥è¡¨å¤´
                headers = detailed_comparison_df.columns.tolist()
                for col, header in enumerate(headers, 1):
                    cell = comparison_sheet.cell(row=4, column=col, value=header)
                    cell.font = header_font
                    cell.fill = header_fill
                    cell.alignment = center_alignment
                
                # å†™å…¥æ•°æ®
                for row_idx, (_, row_data) in enumerate(detailed_comparison_df.iterrows(), 5):
                    for col_idx, value in enumerate(row_data, 1):
                        cell = comparison_sheet.cell(row=row_idx, column=col_idx, value=value)
                        # ä¸ºå¹³å‡å€¼è¡Œæ·»åŠ ç‰¹æ®Šæ ·å¼
                        if 'å¹³å‡å€¼' in str(value):
                            cell.font = header_font
                            cell.fill = PatternFill(start_color='FFE6CC', end_color='FFE6CC', fill_type='solid')
                
                # è°ƒæ•´åˆ—å®½
                for col in range(1, len(headers) + 1):
                    if col == 1:  # æ•°æ®ç»„åˆ—
                        comparison_sheet.column_dimensions[chr(64 + col)].width = 12
                    elif 'æ”¹è¿›ç‡' in headers[col-1]:  # æ”¹è¿›ç‡åˆ—
                        comparison_sheet.column_dimensions[chr(64 + col)].width = 14
                    elif 'ä½ç½®è¯¯å·®' in headers[col-1] or 'å§¿æ€è¯¯å·®' in headers[col-1]:  # ä½ç½®/å§¿æ€è¯¯å·®åˆ—
                        comparison_sheet.column_dimensions[chr(64 + col)].width = 18
                    else:  # å…¶ä»–è¯¯å·®åˆ—
                        comparison_sheet.column_dimensions[chr(64 + col)].width = 16
                
                # ä¸ºæ‰€æœ‰æœ‰æ•°æ®çš„å•å…ƒæ ¼æ·»åŠ è¾¹æ¡†
                for row in comparison_sheet.iter_rows():
                    for cell in row:
                        if cell.value is not None:
                            cell.border = thin_border
            
            # åˆ é™¤é»˜è®¤çš„Sheet
            if 'Sheet' in workbook.sheetnames:
                workbook.remove(workbook['Sheet'])
        
        print(f"âœ… ä¼˜åŒ–ç»“æœæ±‡æ€»Excelæ–‡ä»¶å·²ç”Ÿæˆ: {excel_filepath}")
        print("ğŸ“Š Excelæ–‡ä»¶åŒ…å«å®Œæ•´çš„ä¼˜åŒ–åˆ†æ:")
        print("   ğŸ”§ æœºå™¨äººDHå‚æ•°æ ‡å®šç»“æœ - 6ä¸ªå…³èŠ‚çš„å®Œæ•´DHå‚æ•°")
        print("   ğŸ¯ å·¥å…·ä¸­å¿ƒç‚¹(TCP)ä½å§¿ - ä½ç§»+å››å…ƒæ•°è¡¨ç¤º") 
        print("   ğŸ“ æ¿€å…‰è·Ÿè¸ªä»ªåŸºåº§ä½å§¿ - åŸºåº§åæ ‡ç³»å˜æ¢å‚æ•°")
        if detailed_comparison_df is not None:
            print("   ğŸ“Š ä¼˜åŒ–å‰åè¯¦ç»†å¯¹æ¯” - é€ç»„æ•°æ®è¯¯å·®åˆ†æå’Œæ”¹è¿›ç‡")
        print("   âœ¨ ä¸“ä¸šæ ¼å¼åŒ–ï¼šå›¾æ ‡æ ‡è¯†ã€å•ä½æ ‡æ³¨ã€è¾¹æ¡†ç¾åŒ–")
        print("   ğŸ“‹ å¤šå·¥ä½œè¡¨å±•ç¤ºï¼Œå…¨é¢åˆ†æä¼˜åŒ–æ•ˆæœ")
        
    except ImportError:
        print("âš ï¸  æœªå®‰è£…pandasåº“ï¼Œæ— æ³•ç”ŸæˆExcelæ±‡æ€»æ–‡ä»¶")
        print("   è¯·è¿è¡Œ: pip install pandas openpyxl")
    except Exception as e:
        print(f"âš ï¸  ç”ŸæˆExcelæ±‡æ€»æ–‡ä»¶æ—¶å‡ºé”™: {e}")

#! ä½¿ç”¨å¢å¹¿ç³»ç»ŸSVDæ±‚è§£LMé—®é¢˜
def solve_lm_augmented_svd(J_opt, error_vector, lambda_val, damping_type=None, svd_threshold=None, verbose=None):
    """
    ä½¿ç”¨å¢å¹¿ç³»ç»ŸSVDæ±‚è§£Levenberg-Marquardté—®é¢˜
    
    æ”¯æŒä¸¤ç§é˜»å°¼å½¢å¼ï¼š
    1. Marquardté˜»å°¼ï¼šH = J^T*J + Î» * diag(J^T*J) ï¼ˆé€‚åˆå¤šå°ºåº¦å‚æ•°ï¼‰
    2. Levenbergé˜»å°¼ï¼šH = J^T*J + Î» * I ï¼ˆé€‚åˆåŒå°ºåº¦å‚æ•°ï¼‰
    
    å‚æ•°:
    J_opt: é›…å¯æ¯”çŸ©é˜µï¼ˆåªåŒ…å«å¯ä¼˜åŒ–å‚æ•°çš„åˆ—ï¼‰
    error_vector: è¯¯å·®å‘é‡  
    lambda_val: é˜»å°¼å› å­
    damping_type: "marquardt" æˆ– "levenberg"ï¼Œé˜»å°¼ç±»å‹ï¼ˆNoneæ—¶ä½¿ç”¨é»˜è®¤å€¼ï¼‰
    svd_threshold: å¥‡å¼‚å€¼é˜ˆå€¼ï¼Œå°äºæ­¤å€¼çš„å¥‡å¼‚å€¼è¢«ç½®é›¶ï¼ˆNoneæ—¶ä½¿ç”¨é»˜è®¤å€¼ï¼‰
    verbose: æ˜¯å¦æ‰“å°SVDè¯Šæ–­ä¿¡æ¯ï¼ˆNoneæ—¶ä½¿ç”¨é»˜è®¤å€¼ï¼‰
    
    è¿”å›:
    delta: å‚æ•°æ›´æ–°é‡
    svd_info: SVDè¯Šæ–­ä¿¡æ¯å­—å…¸
    """
    # ä½¿ç”¨å›ºå®šé»˜è®¤å€¼
    if damping_type is None:
        damping_config = get_damping_config()
        damping_type = damping_config.get('damping_type', 'marquardt')
    if svd_threshold is None:
        svd_threshold = 1e-12  # å›ºå®šé»˜è®¤å€¼
    if verbose is None:
        verbose = True  # å›ºå®šé»˜è®¤å€¼
    
    n_residuals, n_params = J_opt.shape
    lambda_tensor = torch.tensor(lambda_val, dtype=J_opt.dtype, device=J_opt.device)
    
    if damping_type == "marquardt":
        # Marquardté˜»å°¼ï¼šH = J^T*J + Î» * diag(J^T*J)
        # å¢å¹¿ç³»ç»Ÿç­‰ä»·å½¢å¼ï¼š[J; âˆš(Î» * diag(J^T*J))]
        JTJ = torch.matmul(J_opt.transpose(0, 1), J_opt)
        diag_JTJ = torch.diag(JTJ)
        # é¿å…å¯¹è§’å…ƒç´ ä¸ºé›¶çš„æƒ…å†µï¼ˆä¿æŠ¤æ•°å€¼ç¨³å®šæ€§ï¼‰
        diag_JTJ = torch.where(diag_JTJ > 1e-12, diag_JTJ, torch.tensor(1e-12, dtype=J_opt.dtype, device=J_opt.device))
        sqrt_diag = torch.sqrt(lambda_tensor * diag_JTJ)
        regularization_matrix = torch.diag(sqrt_diag)
    else:  # levenbergé˜»å°¼
        # Levenbergé˜»å°¼ï¼šä½¿ç”¨å•ä½çŸ©é˜µ
        sqrt_lambda = torch.sqrt(lambda_tensor)
        regularization_matrix = sqrt_lambda * torch.eye(n_params, dtype=J_opt.dtype, device=J_opt.device)
    
    # æ„å»ºå¢å¹¿é›…å¯æ¯”çŸ©é˜µï¼š[J; D^(1/2)]
    J_aug = torch.vstack([J_opt, regularization_matrix])
    
    # æ„å»ºå¢å¹¿è¯¯å·®å‘é‡ï¼š[-e; 0] ï¼ˆæ³¨æ„è´Ÿå·ï¼Œå› ä¸ºæˆ‘ä»¬æ±‚è§£çš„æ˜¯ min ||J*Î´ + e||Â²ï¼‰
    zero_vector = torch.zeros(n_params, dtype=error_vector.dtype, device=error_vector.device)
    e_aug = torch.cat([-error_vector, zero_vector])
    
    # SVDåˆ†è§£
    U, S, Vt = torch.linalg.svd(J_aug, full_matrices=False)
    
    # å¤„ç†å¥‡å¼‚å€¼ï¼šè®¾ç½®é˜ˆå€¼é¿å…æ•°å€¼ä¸ç¨³å®š
    S_inv = torch.where(S > svd_threshold, 1.0/S, 0.0)
    effective_rank = torch.sum(S > svd_threshold).item()
    condition_number = S[0].item() / S[effective_rank-1].item() if effective_rank > 0 else float('inf')
    
    # æ±‚è§£delta = V * S^(-1) * U^T * e_aug
    delta = Vt.T @ torch.diag(S_inv) @ U.T @ e_aug
    
    # æ„å»ºè¯Šæ–­ä¿¡æ¯
    svd_info = {
        'max_singular_value': S[0].item(),
        'min_singular_value': S[-1].item(),
        'effective_rank': effective_rank,
        'total_rank': len(S),
        'condition_number': condition_number,
        'lambda_val': lambda_val
    }
    
    if verbose:
        print(f"    SVDè¯Šæ–­: æœ‰æ•ˆç§©={effective_rank}/{len(S)}, æ¡ä»¶æ•°={condition_number:.2e}, "
              f"Î»={lambda_val:.2e}")
    
    return delta, svd_info

#! ä¿å­˜deltaå€¼åˆ°CSVæ–‡ä»¶
def save_delta_to_csv(delta, iteration, opt_indices, csv_file, lambda_val=None, error_val=None, alt_iteration=None, opt_step=None):
    """
    å°†deltaå€¼ä¿å­˜åˆ°CSVæ–‡ä»¶
    
    å‚æ•°:
    delta: å‚æ•°æ›´æ–°é‡
    iteration: å½“å‰è¿­ä»£æ¬¡æ•°
    opt_indices: å¯ä¼˜åŒ–å‚æ•°çš„ç´¢å¼•
    csv_file: CSVæ–‡ä»¶è·¯å¾„
    lambda_val: å½“å‰é˜»å°¼å› å­å€¼ï¼ˆå¯é€‰ï¼‰
    error_val: å½“å‰è¯¯å·®å€¼ï¼ˆå¯é€‰ï¼‰
    alt_iteration: äº¤æ›¿ä¼˜åŒ–å¾ªç¯æ¬¡æ•°ï¼ˆå¯é€‰ï¼‰
    opt_step: ä¼˜åŒ–æ­¥éª¤ï¼ˆ1æˆ–2ï¼Œå¯é€‰ï¼‰
    """
    try:
        # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        csv_dir = os.path.dirname(csv_file)
        if csv_dir and not os.path.exists(csv_dir):
            os.makedirs(csv_dir)
            
        # åˆ›å»ºå®Œæ•´çš„deltaæ•°ç»„ï¼ˆ38ä¸ªå‚æ•°ï¼‰
        full_delta = np.zeros(38)
        for i, idx in enumerate(opt_indices):
            full_delta[idx] = delta[i]
        
        # å†™å…¥CSVæ–‡ä»¶
        with open(csv_file, 'a', newline='') as f:
            writer = csv.writer(f)
            row = []
            # åªæ·»åŠ deltaå€¼ï¼Œä¸æ·»åŠ è¿­ä»£ä¿¡æ¯ã€lambdaå’Œè¯¯å·®å€¼
            row.extend(full_delta)
            writer.writerow(row)
    except Exception as e:
        print(f"ä¿å­˜deltaå€¼åˆ°CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")

#! LMä¼˜åŒ–
def optimize_dh_parameters(initial_params, max_iterations=None, lambda_init=None, tol=None, opt_indices=None, max_theta_delta_rad=None, csv_file=None, alt_iteration=None, opt_step=None):
    """
    LMä¼˜åŒ–å‡½æ•°ï¼Œä¸»è¦ç”¨äºäº¤æ›¿ä¼˜åŒ–çš„å­æ­¥éª¤
    
    å‚æ•°:
    initial_params: åˆå§‹å‚æ•°å€¼
    max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆNoneæ—¶ä½¿ç”¨é»˜è®¤å€¼50ï¼‰
    lambda_init: åˆå§‹é˜»å°¼å› å­ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    tol: æ”¶æ•›é˜ˆå€¼ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    opt_indices: å¯ä¼˜åŒ–å‚æ•°ç´¢å¼•ï¼ˆNoneæ—¶ä¼˜åŒ–æ‰€æœ‰éå›ºå®šå‚æ•°ï¼‰
    max_theta_delta_rad: thetaå‚æ•°æœ€å¤§å˜åŒ–é‡ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    csv_file: CSVè¾“å‡ºæ–‡ä»¶ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    alt_iteration: äº¤æ›¿ä¼˜åŒ–è½®æ¬¡
    opt_step: ä¼˜åŒ–æ­¥éª¤
    """
    # ä»é…ç½®æ–‡ä»¶è¯»å–é»˜è®¤å‚æ•°
    damping_config = get_damping_config()
    convergence_config = get_convergence_config()
    constraints_config = get_constraints_config()
    output_config = get_output_config()
    
    # ä½¿ç”¨ä¼ å…¥å‚æ•°æˆ–é…ç½®/é»˜è®¤å€¼
    if max_iterations is None:
        max_iterations = 50  # å›ºå®šé»˜è®¤å€¼ï¼Œé€‚åˆå­ä¼˜åŒ–æ­¥éª¤
    if lambda_init is None:
        lambda_init = damping_config.get('lambda_init_default', 0.01)
    if tol is None:
        tol = convergence_config.get('parameter_tol', 1e-10)
    if max_theta_delta_rad is None:
        max_theta_delta_rad = get_max_theta_change_radians()
    if csv_file is None and output_config.get('save_delta_values', True):
        csv_file = output_config.get('delta_csv_file', 'results/delta_values.csv')
    
    # è·å–å…¶ä»–é…ç½®å‚æ•°
    max_inner_iterations = convergence_config.get('max_inner_iterations', 10)
    rho_threshold = convergence_config.get('rho_threshold', 0.0)
    lambda_max = damping_config.get('lambda_max', 1e8)
    lambda_min = damping_config.get('lambda_min', 1e-7)
    enable_quat_norm = constraints_config.get('enable_quaternion_normalization', True)
    
    params = torch.tensor(initial_params, dtype=torch.float64, requires_grad=False)
    #* åˆå§‹åŒ–é˜»å°¼å› å­å’ŒåŠ é€Ÿå› å­
    lambda_val = lambda_init
    v_increase = 2  # ç”¨äºå¤±è´¥æ—¶å¢å¤§lambdaçš„åŠ é€Ÿå› å­
    consecutive_failures = 0  # è¿ç»­å¤±è´¥æ¬¡æ•°è®¡æ•°å™¨
    max_consecutive_failures = 3  # è¿ç»­å¤±è´¥æ¬¡æ•°é˜ˆå€¼
    
    #* è¯»å–å…³èŠ‚è§’åº¦å’Œæ¿€å…‰æ•°æ®
    joint_angles = load_joint_angles()
    laser_matrices = get_laser_tool_matrix()
    n_samples = len(joint_angles)
    if n_samples == 0:
        print("é”™è¯¯: æ— æ³•åŠ è½½å…³èŠ‚è§’åº¦æˆ–æ¿€å…‰æ•°æ®ï¼Œæ ·æœ¬æ•°é‡ä¸º0ã€‚")
        return initial_params
    
    #* è®°å½•åˆå§‹å‡æ–¹æ ¹è¯¯å·®
    current_avg_error = compute_total_error_avg(params, joint_angles, laser_matrices) 
    print(f"åˆå§‹å‡æ–¹æ ¹è¯¯å·®ï¼š{current_avg_error.item():.6f}")
    avg_initial_error = current_avg_error.item() 
    
    #* å¤„ç†å¯ä¼˜åŒ–å‚æ•°ç´¢å¼•
    if opt_indices is None:
        opt_indices = list(range(len(initial_params)))
    opt_indices = np.array(opt_indices)
    
    #* LMè¿­ä»£
    for iteration in range(max_iterations):
        all_errors = []
        all_jacobians = []

        #* è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„è¯¯å·®å‘é‡å’Œé›…å¯æ¯”çŸ©é˜µ
        for i in range(n_samples):
            error_vec = compute_error_vector(params, joint_angles[i], laser_matrices[i])
            jacobian = compute_error_vector_jacobian(params.numpy(), joint_angles[i], laser_matrices[i])
            all_errors.append(error_vec)
            all_jacobians.append(jacobian)
        error_vector = torch.cat(all_errors)

        #* å°†æ‰€æœ‰é›…å¯æ¯”çŸ©é˜µå †å æˆä¸€ä¸ªçŸ©é˜µ
        J = torch.vstack(all_jacobians)

        #* ä½¿ç”¨å¢å¹¿SVDæ–¹æ³•æ±‚è§£LMé—®é¢˜ï¼šæ›´ç¨³å®šçš„æ•°å€¼æ–¹æ³•
        J_opt = J[:, opt_indices]
        update_success = False
        inner_iterations = 0
        while not update_success and inner_iterations < max_inner_iterations:
            inner_iterations += 1
            
            #! ä½¿ç”¨å¢å¹¿SVDæ±‚è§£deltaï¼ˆä»é…ç½®è¯»å–é˜»å°¼ç±»å‹ï¼‰
            try:
                delta, svd_info = solve_lm_augmented_svd(J_opt, error_vector, lambda_val)
                
                # æ£€æŸ¥SVDæ±‚è§£è´¨é‡
                if svd_info['effective_rank'] < len(opt_indices) * 0.8:
                    print(f"è­¦å‘Š: æœ‰æ•ˆç§©({svd_info['effective_rank']})è¾ƒä½ï¼Œå¯èƒ½å­˜åœ¨å‚æ•°å†—ä½™")
                
                # ä½¿ç”¨å›ºå®šçš„æ¡ä»¶æ•°é˜ˆå€¼
                condition_threshold = 1e12  # å›ºå®šé»˜è®¤å€¼
                if svd_info['condition_number'] > condition_threshold:
                    print(f"è­¦å‘Š: æ¡ä»¶æ•°å¾ˆå¤§({svd_info['condition_number']:.2e})ï¼Œå¢å¤§é˜»å°¼å› å­")
                    lambda_val *= 5
                    if lambda_val > lambda_max:
                        print(f"é˜»å°¼å› å­è¶…è¿‡é˜ˆå€¼ {lambda_max}ï¼Œæå‰ç»“æŸä¼˜åŒ–")
                        return params.numpy()
                    continue

            except Exception as e:
                print(f"SVDæ±‚è§£é”™è¯¯: {e}ï¼Œå¢å¤§é˜»å°¼å› å­ Î» = {lambda_val} -> {lambda_val * 10}")
                lambda_val *= 10
                if lambda_val > lambda_max:
                    print(f"é˜»å°¼å› å­è¶…è¿‡é˜ˆå€¼ {lambda_max}ï¼Œæå‰ç»“æŸä¼˜åŒ–")
                    return params.numpy()
                continue

            # åº”ç”¨å‚æ•°æ›´æ–°é™åˆ¶ï¼ˆé’ˆå¯¹thetaè§’ï¼‰
            if max_theta_delta_rad is not None and max_theta_delta_rad > 0:
                theta_param_indices_in_full_params = [3, 7, 11, 15, 19, 23]  # DHä¸­theta_offsetçš„ç´¢å¼•
                for i, param_idx_in_full_params_np_val in enumerate(opt_indices):
                    param_idx_in_full_params = int(param_idx_in_full_params_np_val)  # å°†numpyç±»å‹è½¬æ¢ä¸ºint
                    if param_idx_in_full_params in theta_param_indices_in_full_params:
                        current_delta_val = delta[i]
                        # å°†ç‰¹å®šå‚æ•°çš„æ›´æ–°é‡delta[i]é™åˆ¶åœ¨ [-max_theta_delta_rad, +max_theta_delta_rad] èŒƒå›´å†…
                        delta[i] = torch.clamp(current_delta_val, -max_theta_delta_rad, max_theta_delta_rad)

            #* å°è¯•æ›´æ–°
            params_new = params.clone()
            params_new[opt_indices] += delta
            
            #* è®¡ç®—æ–°è¯¯å·®
            new_avg_error = compute_total_error_avg(params_new, joint_angles, laser_matrices)
            
            #* ä½¿ç”¨rhoç­–ç•¥è¿›è¡Œlambdaæ›´æ–°
            # è®¡ç®—å®é™…è¯¯å·®å‡å°‘é‡ï¼ˆåŸºäºè¯¯å·®å¹³æ–¹å’Œï¼‰
            old_error_squared = current_avg_error.item() ** 2 * n_samples  # è½¬æ¢å›æ€»è¯¯å·®å¹³æ–¹å’Œ
            new_error_squared = new_avg_error.item() ** 2 * n_samples
            actual_reduction = old_error_squared - new_error_squared
            
            # è®¡ç®—é¢„æµ‹è¯¯å·®å‡å°‘é‡: delta^T * (lambda * delta + J^T * error_vector)
            JTe = torch.matmul(J_opt.transpose(0, 1), error_vector)  # é‡æ–°è®¡ç®—J^T * e
            grad = JTe  # J^T * error_vector 
            predicted_reduction = torch.dot(delta, lambda_val * delta - grad).item()  # æ³¨æ„è¿™é‡Œç”¨-gradå› ä¸ºJTe=-grad
            
            # è®¡ç®—rhoï¼ˆå¢ç›Šæ¯”ï¼‰
            if abs(predicted_reduction) > 1e-12:  # é¿å…é™¤é›¶
                rho = actual_reduction / predicted_reduction
            else:
                rho = -1.0  # å¼ºåˆ¶æ‹’ç»æ›´æ–°
            
            print(f"  rho = {rho:.4f}, å®é™…å‡å°‘: {actual_reduction:.6f}, é¢„æµ‹å‡å°‘: {predicted_reduction:.6f}")
            
            if rho > rho_threshold:  # æ¥å—æ›´æ–°
                params = params_new
                current_avg_error = new_avg_error
                consecutive_failures = 0  # é‡ç½®è¿ç»­å¤±è´¥è®¡æ•°å™¨
                
                # ä½¿ç”¨Nielsenç­–ç•¥æ›´æ–°lambda: lambda *= max(1/3, 1-(2*rho-1)^3)
                tmp = 2 * rho - 1
                factor = max(1.0/3.0, 1 - tmp * tmp * tmp)
                lambda_val = lambda_val * factor
                lambda_val = max(lambda_val, lambda_min)  # ä½¿ç”¨é…ç½®çš„ä¸‹ç•Œ
                
                update_success = True
                print(f"  âœ… æ¥å—æ›´æ–°, lambda: {lambda_val/factor:.4e} -> {lambda_val:.4e} (Ã—{factor:.3f})")
            else:  # æ‹’ç»æ›´æ–°
                consecutive_failures += 1  # å¢åŠ è¿ç»­å¤±è´¥è®¡æ•°å™¨
                
                # å¢å¤§lambdaï¼Œä½¿ç”¨åŠ é€Ÿæƒ©ç½š
                lambda_val = lambda_val * v_increase
                old_v = v_increase
                v_increase = v_increase * 2  # åŠ é€Ÿå› å­åŠ å€
                update_success = False
                print(f"  âŒ æ‹’ç»æ›´æ–°, lambda: {lambda_val/old_v:.4e} -> {lambda_val:.4e} (Ã—{old_v}), è¿ç»­å¤±è´¥æ¬¡æ•°: {consecutive_failures}")
                
                # æ£€æŸ¥è¿ç»­å¤±è´¥æ¬¡æ•°æ˜¯å¦è¾¾åˆ°é˜ˆå€¼
                if consecutive_failures >= max_consecutive_failures:
                    print(f"è¿ç»­å¤±è´¥ {consecutive_failures} æ¬¡ï¼Œè¾¾åˆ°é˜ˆå€¼ {max_consecutive_failures}ï¼Œæå‰ç»“æŸä¼˜åŒ–")
                    return params.numpy()
            
            # å¦‚æœæ¥å—äº†æ›´æ–°ï¼Œé‡ç½®åŠ é€Ÿå› å­
            if update_success:
                v_increase = 2

                #* TCPå››å…ƒæ•°å½’ä¸€åŒ– 
                if enable_quat_norm and any(idx in opt_indices for idx in range(27, 31)):
                    q_tcp = params[27:31] 
                    norm_q_tcp = torch.linalg.norm(q_tcp)
                    if norm_q_tcp > 1e-9: 
                        params[27:31] = q_tcp / norm_q_tcp
                    else:
                        params[27:31] = torch.tensor([0.0, 0.0, 0.0, 1.0], dtype=params.dtype, device=params.device)
                        print("è­¦å‘Š: TCPå››å…ƒæ•°æ¨¡é•¿æ¥è¿‘äºé›¶ï¼Œå·²é‡ç½®ä¸º[0,0,0,1]")
                
                #* æ¿€å…‰è·Ÿè¸ªä»ª-åŸºåº§å››å…ƒæ•°å½’ä¸€åŒ– 
                if enable_quat_norm and any(idx in opt_indices for idx in range(34, 38)):
                    q_laser_base = params[34:38]
                    norm_q_laser_base = torch.linalg.norm(q_laser_base)
                    if norm_q_laser_base > 1e-9:
                        params[34:38] = q_laser_base / norm_q_laser_base
                    else:
                        params[34:38] = torch.tensor([0.0, 0.0, 0.0, 1.0], dtype=params.dtype, device=params.device)
                        print("è­¦å‘Š: æ¿€å…‰è·Ÿè¸ªä»ª-åŸºåº§å››å…ƒæ•°æ¨¡é•¿æ¥è¿‘äºé›¶ï¼Œå·²é‡ç½®ä¸º[0,0,0,1]")

                # ä¿å­˜deltaå€¼åˆ°CSVæ–‡ä»¶
                if csv_file is not None:
                    save_delta_to_csv(delta.numpy(), iteration+1, opt_indices, csv_file, 
                                     lambda_val=lambda_val, error_val=current_avg_error.item(), 
                                     alt_iteration=alt_iteration, opt_step=opt_step)

                print(f"è¿­ä»£ {iteration+1}: å‡æ–¹æ ¹è¯¯å·® = {current_avg_error.item():.8f}, Î» = {lambda_val:.4e}, \nÎ”Î¸ (å‚æ•°æ”¹å˜é‡) = {delta.numpy()}")            

            #* å¦‚æœé˜»å°¼å› å­è¶…è¿‡ä¸€å®šé˜ˆå€¼ï¼Œæå‰ç»“æŸä¼˜åŒ–
            if lambda_val > lambda_max * 0.1:  # ä½¿ç”¨é…ç½®çš„90%ä½œä¸ºè­¦å‘Šé˜ˆå€¼
                print(f"é˜»å°¼å› å­è¶…è¿‡é˜ˆå€¼ {lambda_max * 0.1:.0e}ï¼Œæå‰ç»“æŸä¼˜åŒ–")
                return params.numpy()
        if not update_success:
            print("å†…éƒ¨è¿­ä»£æœªæ”¶æ•›ï¼Œç»§ç»­ä¸»å¾ªç¯")
  
        if update_success and torch.norm(delta) < tol:
            print(f"å‚æ•°å˜åŒ–å°äºé˜ˆå€¼ {tol}ï¼Œåœ¨ç¬¬ {iteration+1} æ¬¡è¿­ä»£åæ”¶æ•›")
            break

    #* æœ€ç»ˆå‡æ–¹æ ¹è¯¯å·®
    final_avg_error = current_avg_error.item() 
    improvement = (avg_initial_error - final_avg_error) / avg_initial_error * 100 if avg_initial_error > 1e-9 else 0 
    print(f"ä¼˜åŒ–å®Œæˆï¼Œåˆå§‹å‡æ–¹æ ¹è¯¯å·®: {avg_initial_error:.6f}, æœ€ç»ˆå‡æ–¹æ ¹è¯¯å·®: {final_avg_error:.6f}, æ”¹è¿›ç‡: {improvement:.2f}%")
    return params.numpy()

#! äº¤æ›¿ä¼˜åŒ–å‡½æ•°
def alternate_optimize_parameters(initial_params, max_alt_iterations=None, convergence_tol=None, 
                                 max_sub_iterations_group1=None, max_sub_iterations_group2=None,
                                 lambda_init_group1=None, lambda_init_group2=None, max_theta_delta_rad_for_sub_opt=None):
    """
    äº¤æ›¿ä¼˜åŒ–å‡½æ•°ï¼Œå‚æ•°å¯ä»¥ä»é…ç½®æ–‡ä»¶è¯»å–é»˜è®¤å€¼
    
    å‚æ•°:
    initial_params: åˆå§‹å‚æ•°å€¼
    max_alt_iterations: æœ€å¤§äº¤æ›¿è¿­ä»£æ¬¡æ•°ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    convergence_tol: æ”¶æ•›é˜ˆå€¼ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    max_sub_iterations_group1: ç¬¬ä¸€ç»„å‚æ•°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    max_sub_iterations_group2: ç¬¬äºŒç»„å‚æ•°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    lambda_init_group1: ç¬¬ä¸€ç»„å‚æ•°åˆå§‹é˜»å°¼å› å­ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    lambda_init_group2: ç¬¬äºŒç»„å‚æ•°åˆå§‹é˜»å°¼å› å­ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    max_theta_delta_rad_for_sub_opt: thetaå‚æ•°æœ€å¤§å˜åŒ–é‡ï¼ˆNoneæ—¶ä»é…ç½®è¯»å–ï¼‰
    """
    # ä»é…ç½®æ–‡ä»¶è¯»å–é»˜è®¤å‚æ•°
    alt_config = get_alternate_optimization_config()
    damping_config = get_damping_config()
    output_config = get_output_config()
    
    # ä½¿ç”¨ä¼ å…¥å‚æ•°æˆ–é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼
    if max_alt_iterations is None:
        max_alt_iterations = alt_config.get('max_alt_iterations', 4)
    if convergence_tol is None:
        convergence_tol = alt_config.get('convergence_tol', 1e-4)
    if max_sub_iterations_group1 is None:
        max_sub_iterations_group1 = alt_config.get('max_sub_iterations_group1', 10)
    if max_sub_iterations_group2 is None:
        max_sub_iterations_group2 = alt_config.get('max_sub_iterations_group2', 10)
    if lambda_init_group1 is None:
        lambda_init_group1 = damping_config.get('lambda_init_group1', 2.0)
    if lambda_init_group2 is None:
        lambda_init_group2 = damping_config.get('lambda_init_group2', 0.001)
    if max_theta_delta_rad_for_sub_opt is None:
        max_theta_delta_rad_for_sub_opt = get_max_theta_change_radians()
    
    print("\n" + "="*60)
    print(" "*20 + "å¼€å§‹äº¤æ›¿ä¼˜åŒ–")
    print("="*60)
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–CSVæ–‡ä»¶è·¯å¾„
    csv_file = None
    if output_config.get('save_delta_values', True):
        csv_file = output_config.get('delta_csv_file', 'results/delta_values.csv')
    
    # åˆ›å»ºå‚æ•°åç§°åˆ—è¡¨
    param_names = []
    for i in range(6):
        for param in ["alpha", "a", "d", "theta_offset"]:
            param_names.append(f"Joint{i+1}_{param}")
    for param in ["tx", "ty", "tz", "qx", "qy", "qz", "qw"]:
        param_names.append(f"TCP_{param}")
    for param in ["tx", "ty", "tz", "qx", "qy", "qz", "qw"]:
        param_names.append(f"Laser_{param}")
    
    # åˆå§‹åŒ–CSVæ–‡ä»¶
    if csv_file:
        try:
            # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            csv_dir = os.path.dirname(csv_file)
            if csv_dir and not os.path.exists(csv_dir):
                os.makedirs(csv_dir)
                
            with open(csv_file, 'w', newline='') as f:
                writer = csv.writer(f)
                # åªåŒ…å«å‚æ•°åç§°ï¼Œä¸åŒ…å«Iterationã€Lambdaå’ŒError
                header = param_names
                writer.writerow(header)
            print(f"Deltaå€¼å°†ä¿å­˜åˆ°: {csv_file}")
        except Exception as e:
            print(f"åˆ›å»ºCSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            csv_file = None
    
    #* è¯»å–å…³èŠ‚è§’åº¦å’Œæ¿€å…‰æ•°æ®
    joint_angles = load_joint_angles()
    laser_matrices = get_laser_tool_matrix()
    
    #! è·å–å‚æ•°åˆ†ç»„ç´¢å¼•
    opt_indices_group1, opt_indices_group2 = get_parameter_groups(exclude_fixed=True)
    
    #! åˆå§‹åŒ–å‡æ–¹æ ¹è¯¯å·®
    params = np.array(initial_params)
    current_avg_error_val = compute_total_error_avg(params, joint_angles, laser_matrices).item() # å·²ä¿®æ”¹ä¸ºè®¡ç®—å¹³å‡è¯¯å·®, ä½¿ç”¨ .item() è·å–æ•°å€¼
    avg_initial_error_alternate = current_avg_error_val 
    print(f"åˆå§‹å‡æ–¹æ ¹è¯¯å·®: {avg_initial_error_alternate:.6f}")
    
    #* æ‰“å°å‚æ•°ç»„ä¿¡æ¯
    print(f"ç¬¬ä¸€ç»„å‚æ•°ç´¢å¼• (å…±{len(opt_indices_group1)}ä¸ª): {opt_indices_group1}")
    print(f"ç¬¬äºŒç»„å‚æ•°ç´¢å¼• (å…±{len(opt_indices_group2)}ä¸ª): {opt_indices_group2}")
    
    # è®°å½•è¯¯å·®å†å²
    error_history_avg = [avg_initial_error_alternate] # è®°å½•å¹³å‡è¯¯å·®, ä½¿ç”¨æ–°çš„åˆå§‹è¯¯å·®å˜é‡å
    
    #! äº¤æ›¿ä¼˜åŒ–ä¸»å¾ªç¯
    for alt_iteration in range(max_alt_iterations):
        print(f"\n===== äº¤æ›¿ä¼˜åŒ–å¾ªç¯ {alt_iteration + 1}/{max_alt_iterations} =====")
        
        #! ç¬¬ä¸€æ­¥ï¼šä¼˜åŒ–DHå‚æ•° + TCP + æ¿€å…‰XYZï¼Œå›ºå®šæ¿€å…‰å››å…ƒæ•°
        print("\n----- ç¬¬ä¸€æ­¥ï¼šä¼˜åŒ–DHå‚æ•° + TCP + æ¿€å…‰XYZ -----")
        params_step1 = optimize_dh_parameters(
            params, 
            max_iterations=max_sub_iterations_group1, # ä¿®æ”¹ï¼šä½¿ç”¨ç¬¬ä¸€ç»„çš„è¿­ä»£æ¬¡æ•°
            lambda_init=lambda_init_group1, 
            opt_indices=opt_indices_group1,
            max_theta_delta_rad=max_theta_delta_rad_for_sub_opt,
            csv_file=csv_file,
            alt_iteration=alt_iteration+1,
            opt_step=1
        )
        
        #* è®¡ç®—ç¬¬ä¸€æ­¥ä¼˜åŒ–åçš„è¯¯å·®    
        avg_error_step1 = compute_total_error_avg(params_step1, joint_angles, laser_matrices).item() 
        print(f"ç¬¬ä¸€æ­¥åå‡æ–¹æ ¹è¯¯å·®: {avg_error_step1:.6f}")
        
        #! ç¬¬äºŒæ­¥ï¼šä¼˜åŒ–æ¿€å…‰å››å…ƒæ•°ï¼Œå›ºå®šDHå‚æ•°+TCP+æ¿€å…‰XYZ
        print("\n----- ç¬¬äºŒæ­¥ï¼šä¼˜åŒ–æ¿€å…‰å››å…ƒæ•° -----")
        params_step2 = optimize_dh_parameters(
            params_step1, 
            max_iterations=max_sub_iterations_group2, # ä¿®æ”¹ï¼šä½¿ç”¨ç¬¬äºŒç»„çš„è¿­ä»£æ¬¡æ•°
            lambda_init=lambda_init_group2, 
            opt_indices=opt_indices_group2,
            max_theta_delta_rad=max_theta_delta_rad_for_sub_opt,
            csv_file=csv_file,
            alt_iteration=alt_iteration+1,
            opt_step=2
        )
        
        #* è®¡ç®—ç¬¬äºŒæ­¥ä¼˜åŒ–åçš„è¯¯å·®
        avg_error_step2 = compute_total_error_avg(params_step2, joint_angles, laser_matrices).item() 
        print(f"ç¬¬äºŒæ­¥åå‡æ–¹æ ¹è¯¯å·®: {avg_error_step2:.6f}")
        
        #* æ›´æ–°è¯¯å·®
        params = params_step2
        error_history_avg.append(avg_error_step2) 
        
        #* è®¡ç®—è¯¯å·®æ”¹è¿›é‡
        error_improvement = error_history_avg[-2] - error_history_avg[-1] 
        relative_improvement = error_improvement / error_history_avg[-2] if error_history_avg[-2] > 1e-9 else 0
        
        print(f"\næœ¬æ¬¡å¾ªç¯è¯¯å·®æ”¹è¿›: {error_improvement:.6f}, ç›¸å¯¹æ”¹è¿›: {relative_improvement*100:.4f}%")
        
        if error_improvement < convergence_tol:
            print(f"\nè¯¯å·®æ”¹è¿› {error_improvement:.6f} å°äºé˜ˆå€¼ {convergence_tol}ï¼Œäº¤æ›¿ä¼˜åŒ–æ”¶æ•›")
            break
            
    #* è®¡ç®—æ€»ä½“ä¼˜åŒ–æ•ˆæœ
    final_avg_error_alternate = error_history_avg[-1] 
    total_improvement = (avg_initial_error_alternate - final_avg_error_alternate) / avg_initial_error_alternate * 100 if avg_initial_error_alternate > 1e-9 else 0
    
    print("\n" + "="*60)
    print(f"äº¤æ›¿ä¼˜åŒ–å®Œæˆï¼Œå…±è¿›è¡Œäº† {alt_iteration + 1} æ¬¡å¾ªç¯")
    print(f"åˆå§‹å‡æ–¹æ ¹è¯¯å·®: {avg_initial_error_alternate:.6f}") 
    print(f"æœ€ç»ˆå‡æ–¹æ ¹è¯¯å·®: {final_avg_error_alternate:.6f}")
    print(f"æ€»ä½“æ”¹è¿›ç‡: {total_improvement:.2f}%")
    print("="*60)
    
    return params

def evaluate_optimization(initial_params, optimized_params):
    """è¯„ä¼°ä¼˜åŒ–æ•ˆæœï¼ŒæŠ¥å‘Šä¸ä¼˜åŒ–å™¨ç›®æ ‡ä¸€è‡´çš„å‡æ–¹æ ¹è¯¯å·®"""
    # è¯»å–æ•°æ®
    joint_angles = load_joint_angles()
    laser_matrices = get_laser_tool_matrix()
    n_samples = len(joint_angles)

    if n_samples == 0:
        print("è¯„ä¼°è­¦å‘Š: æ ·æœ¬æ•°é‡ä¸º0ï¼Œæ— æ³•è¿›è¡Œè¯„ä¼°ã€‚")
        return
    
    print("\n" + "="*60) # è°ƒæ•´åˆ†éš”çº¿é•¿åº¦ä»¥é€‚åº”æ–°çš„è¡¨å¤´ 
    print(" "*15 + "ä¼˜åŒ–æ•ˆæœè¯„ä¼° (æ‰€æœ‰åˆ†é‡çš„å‡æ–¹æ ¹è¯¯å·®)") # ä¿®æ”¹æ ‡é¢˜
    print("="*60)
    # æ‰“å°è¡¨å¤´ï¼Œæ˜ç¡®æŒ‡å‡ºæ€»ä½“å¹³å‡è¯¯å·®æ˜¯å‡æ–¹æ ¹è¯¯å·®
    print(f"{'å§¿æ€(å¸§)':^12}|{'åˆå§‹å•å¸§èŒƒæ•°':^18}|{'ä¼˜åŒ–åå•å¸§èŒƒæ•°':^20}|{'å•å¸§æ”¹è¿›ç‡':^15}")
    print("-"*68) # è°ƒæ•´åˆ†éš”çº¿é•¿åº¦
    
    # è®¡ç®—åˆå§‹å’Œä¼˜åŒ–åçš„æ€»ä½“å‡æ–¹æ ¹è¯¯å·® (ä¸compute_total_error_avgä¸€è‡´)
    initial_total_rmse = compute_total_error_avg(initial_params, joint_angles, laser_matrices).item()
    optimized_total_rmse = compute_total_error_avg(optimized_params, joint_angles, laser_matrices).item()

    # é€å¸§æ˜¾ç¤ºè¯¯å·®èŒƒæ•°åŠå…¶æ”¹è¿›ï¼Œç”¨äºè¯¦ç»†åˆ†æ
    for i in range(n_samples):
        initial_error_vec = compute_error_vector(initial_params, joint_angles[i], laser_matrices[i])
        optimized_error_vec = compute_error_vector(optimized_params, joint_angles[i], laser_matrices[i])
        
        initial_frame_norm = torch.linalg.norm(initial_error_vec).item()
        optimized_frame_norm = torch.linalg.norm(optimized_error_vec).item()
        
        frame_improvement = (1 - optimized_frame_norm / initial_frame_norm) * 100 if initial_frame_norm > 1e-9 else 0
        
        print(f"{i+1:^12}|{initial_frame_norm:^18.6f}|{optimized_frame_norm:^20.6f}|{frame_improvement:^14.2f}%")
    
    # è®¡ç®—æ€»ä½“æ”¹è¿›ç‡ (åŸºäºå‡æ–¹æ ¹è¯¯å·®)
    avg_improvement_rmse = (1 - optimized_total_rmse / initial_total_rmse) * 100 if initial_total_rmse > 1e-9 else 0
    
    print("-"*68) # è°ƒæ•´åˆ†éš”çº¿é•¿åº¦
    print(f"{'æ€»ä½“å¹³å‡RMSE':^12}|{initial_total_rmse:^18.6f}|{optimized_total_rmse:^20.6f}|{avg_improvement_rmse:^14.2f}%")
    print("="*60)


if __name__ == '__main__':
    initial_params = get_initial_params()

    # è·å–å¯ä¼˜åŒ–å‚æ•°ç´¢å¼•
    opt_indices = get_optimizable_indices()
    fixed_indices = get_fixed_indices()  # ç›´æ¥è°ƒç”¨å‡½æ•°è·å–
    print(f"å›ºå®šå‚æ•°ç´¢å¼• ({len(fixed_indices)}): {fixed_indices}")
    print(f"å¯ä¼˜åŒ–å‚æ•°ç´¢å¼• ({len(opt_indices)}): {opt_indices}")
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–thetaå‚æ•°æœ€å¤§å˜åŒ–é‡
    max_theta_change_radians = get_max_theta_change_radians()
    max_theta_change_degrees = np.rad2deg(max_theta_change_radians)
    print(f"Thetaå‚æ•°å•æ­¥æœ€å¤§å˜åŒ–é‡: {max_theta_change_degrees:.1f}åº¦ ({max_theta_change_radians:.6f}å¼§åº¦)")
    
    # ä½¿ç”¨äº¤æ›¿ä¼˜åŒ–æ–¹æ³• - ç°åœ¨æ‰€æœ‰å‚æ•°éƒ½ä»é…ç½®æ–‡ä»¶è¯»å–
    optimized_params = alternate_optimize_parameters(initial_params)

    # ä¿å­˜ä¼˜åŒ–ç»“æœ - è·¯å¾„ä»é…ç½®æ–‡ä»¶è¯»å–
    save_optimization_results(optimized_params, initial_params) 

    # è¯„ä¼°ä¼˜åŒ–æ•ˆæœ 
    evaluate_optimization(initial_params, optimized_params)
    
    # è¾“å‡ºä¼˜åŒ–å‰åçš„å‚æ•°å¯¹æ¯”
    print("\n" + "="*70)
    print(" "*25 + "DHå‚æ•°å¯¹æ¯”")
    print("="*70)
    print(f"{'å…³èŠ‚':^6}|{'å‚æ•°':^12}|{'åˆå§‹å€¼':^15}|{'ä¼˜åŒ–å€¼':^15}|{'å·®å¼‚':^15}|{'çŠ¶æ€':^10}")
    print("-"*70)
    
    param_names = ["alpha", "a", "d", "theta_offset"]
    
    # å°†å‚æ•°é‡æ„ä¸º6Ã—4çŸ©é˜µï¼Œæ–¹ä¾¿æŸ¥çœ‹ (DHéƒ¨åˆ†)
    init_dh_matrix = initial_params[0:24].reshape(6, 4)
    opt_dh_matrix = optimized_params[0:24].reshape(6, 4)
    
    for i in range(6):  
        for j in range(4):  
            param_idx = i * 4 + j  
            param_diff = opt_dh_matrix[i, j] - init_dh_matrix[i, j]
            status = "å·²ä¼˜åŒ–" if param_idx in opt_indices else "å·²å›ºå®š"
            print(f"{i+1:^6}|{param_names[j]:^12}|{init_dh_matrix[i, j]:^15.4f}|{opt_dh_matrix[i, j]:^15.4f}|{param_diff:^15.4f}|{status:^10}")
        if i < 5:  
            print("-"*70)
    
    # æ·»åŠ TCPå‚æ•°å¯¹æ¯”
    print("="*70)
    print(" "*25 + "TCP å‚æ•°å¯¹æ¯”")
    print("="*70)
    tcp_param_names = ["tx", "ty", "tz", "qx", "qy", "qz", "qw"]
    init_tcp_params = initial_params[24:31]
    opt_tcp_params = optimized_params[24:31]
    for k in range(7):
        tcp_idx = 24 + k
        tcp_diff = opt_tcp_params[k] - init_tcp_params[k]
        status = "å·²ä¼˜åŒ–" if tcp_idx in opt_indices else "å·²å›ºå®š"
        print(f"{'-':^6}|{tcp_param_names[k]:^12}|{init_tcp_params[k]:^15.4f}|{opt_tcp_params[k]:^15.4f}|{tcp_diff:^15.4f}|{status:^10}")

    # æ·»åŠ æ¿€å…‰è·Ÿè¸ªä»ª-åŸºåº§å˜æ¢å‚æ•°å¯¹æ¯”
    print("="*70)
    print(" "*25 + "æ¿€å…‰è·Ÿè¸ªä»ª-åŸºåº§å˜æ¢å‚æ•°å¯¹æ¯”")
    print("="*70)
    t_laser_base_param_names = ["tx", "ty", "tz", "qx", "qy", "qz", "qw"]
    init_t_laser_base_params = initial_params[31:38]
    opt_t_laser_base_params = optimized_params[31:38]
    for k in range(7):
        t_laser_base_idx = 31 + k
        t_laser_base_diff = opt_t_laser_base_params[k] - init_t_laser_base_params[k]
        status = "å·²ä¼˜åŒ–" if t_laser_base_idx in opt_indices else "å·²å›ºå®š"
        print(f"{'-':^6}|{t_laser_base_param_names[k]:^12}|{init_t_laser_base_params[k]:^15.4f}|{opt_t_laser_base_params[k]:^15.4f}|{t_laser_base_diff:^15.4f}|{status:^10}")

    print("="*70)