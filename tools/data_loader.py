import os
import re
import numpy as np
import pandas as pd
import yaml
from scipy.spatial.transform import Rotation
import ast

# æ·»åŠ Excelæ”¯æŒå’Œç¼–ç æ£€æµ‹
try:
    import openpyxl  # Excelæ”¯æŒ
except ImportError:
    openpyxl = None
    print("è­¦å‘Š: æœªå®‰è£…openpyxlï¼ŒExcelæ ¼å¼æ”¯æŒä¸å¯ç”¨")

try:
    import chardet  # ç¼–ç æ£€æµ‹
except ImportError:
    chardet = None
    print("è­¦å‘Š: æœªå®‰è£…chardetï¼Œç¼–ç æ£€æµ‹ä¸å¯ç”¨")

# é»˜è®¤é…ç½®æ–‡ä»¶è·¯å¾„
DEFAULT_CONFIG_FILE = 'config/config.yaml'

# å…¨å±€é…ç½®å˜é‡
_config = None

# å…¨å±€ç¼“å­˜å˜é‡
_joint_limits_cache = None

class SmartFormatDetector:
    """æ™ºèƒ½æ ¼å¼æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.rokae_pattern = re.compile(r'LOCAL VAR jointtarget.*?j:\s*{\s*([^}]*?)\s*}')
        
    def detect_format(self, file_path):
        """æ£€æµ‹æ–‡ä»¶æ ¼å¼"""
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        ext = os.path.splitext(file_path)[1].lower()
        
        if ext == '.txt':
            return 'txt'
        elif ext in ['.xlsx', '.xls']:
            return 'excel'
        elif ext == '.csv':
            if self._is_rokae_format(file_path):
                return 'rokae_csv'
            else:
                return 'csv'
        else:
            return 'csv'  # é»˜è®¤å°è¯•CSVæ ¼å¼
    
    def _is_rokae_format(self, file_path):
        """æ£€æµ‹å…³èŠ‚è§’åº¦æ˜¯å¦ä¸ºrokaeæœºå™¨äººæ ¼å¼"""
        try:
            encoding = self.detect_encoding(file_path)
            with open(file_path, 'r', encoding=encoding) as f:
                first_lines = f.read(500)
                return 'LOCAL VAR jointtarget' in first_lines
        except:
            return False
    
    def detect_encoding(self, file_path):
        """æ£€æµ‹æ–‡ä»¶ç¼–ç """
        if chardet is None:
            return 'utf-8'
        try:
            with open(file_path, 'rb') as f:
                raw_data = f.read(10000)
                result = chardet.detect(raw_data)
                return result.get('encoding', 'utf-8')
        except:
            return 'utf-8'
    
    def detect_delimiter(self, file_path):
        """æ£€æµ‹åˆ†éš”ç¬¦"""
        encoding = self.detect_encoding(file_path)
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                sample = f.read(1024)
            
            delimiters = [',', '\t', ' ', ';', '|']
            delimiter_counts = {}
            
            for delimiter in delimiters:
                count = sample.count(delimiter)
                if count > 0:
                    delimiter_counts[delimiter] = count
            
            if not delimiter_counts:
                return ','
            
            return max(delimiter_counts, key=delimiter_counts.get)
        except:
            return ','

class SmartDataParser:
    """æ™ºèƒ½æ•°æ®è§£æå™¨"""
    
    def __init__(self):
        self.detector = SmartFormatDetector()
        self.config = get_config()
    
    def parse_joint_angles(self, file_path):
        """è§£æå…³èŠ‚è§’åº¦æ•°æ®"""
        file_format = self.detector.detect_format(file_path)
        
        try:
            if file_format == 'rokae_csv':
                return self._parse_rokae_joint_angles(file_path)
            elif file_format == 'csv':
                return self._parse_csv_joint_angles(file_path)
            elif file_format == 'txt':
                return self._parse_txt_joint_angles(file_path)  
            elif file_format == 'excel':
                return self._parse_excel_joint_angles(file_path)
            else:
                # å›é€€åˆ°åŸå§‹æ ¼å¼è§£æ
                return self._parse_rokae_joint_angles(file_path)
        except Exception as e:
            print(f"æ™ºèƒ½è§£æå¤±è´¥ï¼Œå°è¯•åŸå§‹æ ¼å¼: {e}")
            return self._parse_rokae_joint_angles(file_path)
    
    def parse_positions(self, file_path):
        """è§£æä½ç½®æ•°æ®"""
        file_format = self.detector.detect_format(file_path)
        
        try:
            if file_format == 'csv':
                return self._parse_csv_positions(file_path)
            elif file_format == 'txt':
                return self._parse_txt_positions(file_path)
            elif file_format == 'excel':
                return self._parse_excel_positions(file_path)
            else:
                # å›é€€åˆ°åŸå§‹æ¿€å…‰è·Ÿè¸ªä»ªæ ¼å¼
                return self._parse_laser_tracker_positions(file_path)
        except Exception as e:
            print(f"æ™ºèƒ½è§£æå¤±è´¥ï¼Œå°è¯•åŸå§‹æ¿€å…‰è·Ÿè¸ªä»ªæ ¼å¼: {e}")
            return self._parse_laser_tracker_positions(file_path)
    
    def _parse_rokae_joint_angles(self, file_path):
        """è§£ærokaeæ ¼å¼å…³èŠ‚è§’åº¦ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        config = self.config.get('data_input', {}).get('joint_angles', {}).get('rokae_format', {})
        pattern_str = config.get('pattern', r'j:\s*{\s*([^}]*?)\s*}')
        pattern = re.compile(pattern_str)
        
        joint_angles = []
        encoding = self.detector.detect_encoding(file_path)
        
        with open(file_path, 'r', encoding=encoding) as f:
            for line_num, line in enumerate(f, 1):
                match = pattern.search(line)
                if match:
                    content_in_braces = match.group(1)
                    angles_str = [angle.strip() for angle in content_in_braces.split(',')]
                    
                    if len(angles_str) >= 6:
                        try:
                            extracted_angles = [float(angle) for angle in angles_str[:6] if angle]
                            if len(extracted_angles) == 6:
                                joint_angles.append(extracted_angles)
                        except ValueError as e:
                            print(f"è­¦å‘Š: ç¬¬{line_num}è¡Œæ•°å€¼è½¬æ¢é”™è¯¯: {e}")
        
        if not joint_angles:
            raise ValueError("æœªèƒ½æå–å…³èŠ‚è§’åº¦æ•°æ®")
        
        result = np.array(joint_angles)
        print(f"âœ… rokaeæ ¼å¼åŠ è½½å…³èŠ‚è§’åº¦: {result.shape[0]}ç»„æ•°æ®")
        return result
    
    def _parse_csv_joint_angles(self, file_path):
        """è§£æCSVæ ¼å¼å…³èŠ‚è§’åº¦"""
        encoding = self.detector.detect_encoding(file_path)
        df = pd.read_csv(file_path, encoding=encoding)
        
        # æ™ºèƒ½å­—æ®µè¯†åˆ«
        joint_data = self._extract_joint_angles_from_df(df)
        print(f"âœ… CSVæ ¼å¼åŠ è½½å…³èŠ‚è§’åº¦: {joint_data.shape[0]}ç»„æ•°æ®")
        return joint_data
    
    def _parse_txt_joint_angles(self, file_path):
        """è§£æTXTæ ¼å¼å…³èŠ‚è§’åº¦"""
        encoding = self.detector.detect_encoding(file_path)
        delimiter = self.detector.detect_delimiter(file_path)
        
        # å…ˆæ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦åŒ…å«åˆ—åï¼ˆå¦‚J1,J2ç­‰ï¼‰
        with open(file_path, 'r', encoding=encoding) as f:
            first_line = f.readline().strip()
        
        # å¦‚æœç¬¬ä¸€è¡ŒåŒ…å«å­—æ¯ï¼ˆå¯èƒ½æ˜¯åˆ—åï¼‰ï¼Œä½¿ç”¨header=0ï¼Œå¦åˆ™ä½¿ç”¨header=None
        if any(c.isalpha() for c in first_line):
            df = pd.read_csv(file_path, delimiter=delimiter, encoding=encoding, header=0)
        else:
            df = pd.read_csv(file_path, delimiter=delimiter, encoding=encoding, 
                            header=None, comment='#')
        
        joint_data = self._extract_joint_angles_from_df(df)
        print(f"âœ… TXTæ ¼å¼åŠ è½½å…³èŠ‚è§’åº¦: {joint_data.shape[0]}ç»„æ•°æ®")
        return joint_data
    
    def _parse_excel_joint_angles(self, file_path):
        """è§£æExcelæ ¼å¼å…³èŠ‚è§’åº¦"""
        if openpyxl is None:
            raise ImportError("éœ€è¦å®‰è£…openpyxlæ¥æ”¯æŒExcelæ ¼å¼")
        
        df = pd.read_excel(file_path, sheet_name=0)
        joint_data = self._extract_joint_angles_from_df(df)
        print(f"âœ… Excelæ ¼å¼åŠ è½½å…³èŠ‚è§’åº¦: {joint_data.shape[0]}ç»„æ•°æ®")
        return joint_data
    
    def _extract_joint_angles_from_df(self, df):
        """ä»DataFrameæ™ºèƒ½æå–å…³èŠ‚è§’åº¦æ•°æ®"""
        config = self.config.get('data_input', {}).get('joint_angles', {})
        field_patterns = config.get('field_patterns', [
            ["joint1", "joint2", "joint3", "joint4", "joint5", "joint6"],
            ["J1", "J2", "J3", "J4", "J5", "J6"],
        ])
        
        # å°è¯•é€šè¿‡åˆ—ååŒ¹é…
        joint_columns = []
        for pattern in field_patterns:
            matching_cols = []
            for col_name in pattern:
                for df_col in df.columns:
                    if col_name.lower() in str(df_col).lower():
                        matching_cols.append(df_col)
                        break
            if len(matching_cols) == 6:
                joint_columns = matching_cols
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„åˆ—åï¼Œä½¿ç”¨å‰6åˆ—
        if not joint_columns:
            if df.shape[1] >= 6:
                joint_columns = df.columns[:6].tolist()
            else:
                raise ValueError(f"æ•°æ®åˆ—æ•°ä¸è¶³ï¼Œéœ€è¦è‡³å°‘6åˆ—ï¼Œå®é™…{df.shape[1]}åˆ—")
        
        # æå–æ•°æ®å¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„
        joint_data = df[joint_columns].values.astype(float)
        
        if joint_data.shape[1] != 6:
            raise ValueError(f"å…³èŠ‚è§’åº¦æ•°æ®åˆ—æ•°é”™è¯¯ï¼ŒæœŸæœ›6åˆ—ï¼Œå®é™…{joint_data.shape[1]}åˆ—")
        
        return joint_data
    
    def _parse_laser_tracker_positions(self, file_path):
        """è§£ææ¿€å…‰è·Ÿè¸ªä»ªæ ¼å¼ä½ç½®æ•°æ®ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰"""
        config = self.config.get('data_input', {}).get('positions', {}).get('laser_tracker', {})
        measurement_columns = config.get('measurement_columns', [7, 8, 9, 10, 11, 12])
        
        laser_positions = []
        encoding = self.detector.detect_encoding(file_path)
        
        with open(file_path, 'r', encoding=encoding) as f:
            for line_num, line in enumerate(f, start=2):
                stripped_line = line.strip()
                if not stripped_line:
                    continue
                
                parts = stripped_line.split()
                parts = [part.strip() for part in parts if part.strip()]
                
                if len(parts) > max(measurement_columns):
                    try:
                        measured_data = [float(parts[i]) for i in measurement_columns]
                        laser_positions.append(measured_data)
                    except (ValueError, IndexError) as e:
                        print(f"è­¦å‘Š: ç¬¬{line_num}è¡Œæ•°æ®è§£æé”™è¯¯: {e}")
        
        if not laser_positions:
            raise ValueError("æœªèƒ½æå–æ¿€å…‰ä½ç½®æ•°æ®")
        
        result = np.array(laser_positions)
        print(f"âœ… æ¿€å…‰è·Ÿè¸ªä»ªæ ¼å¼åŠ è½½ä½ç½®æ•°æ®: {result.shape[0]}ç»„æ•°æ®")
        return result
    
    def _parse_csv_positions(self, file_path):
        """è§£æCSVæ ¼å¼ä½ç½®æ•°æ®"""
        encoding = self.detector.detect_encoding(file_path)
        df = pd.read_csv(file_path, encoding=encoding)
        
        position_data = self._extract_positions_from_df(df)
        print(f"âœ… CSVæ ¼å¼åŠ è½½ä½ç½®æ•°æ®: {position_data.shape[0]}ç»„æ•°æ®")
        return position_data
    
    def _parse_txt_positions(self, file_path):
        """è§£æTXTæ ¼å¼ä½ç½®æ•°æ®"""
        encoding = self.detector.detect_encoding(file_path)
        delimiter = self.detector.detect_delimiter(file_path)
        
        # å…ˆæ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦åŒ…å«åˆ—åï¼ˆå¦‚X,Y,Zç­‰ï¼‰
        with open(file_path, 'r', encoding=encoding) as f:
            first_line = f.readline().strip()
        
        # å¦‚æœç¬¬ä¸€è¡ŒåŒ…å«å­—æ¯ï¼ˆå¯èƒ½æ˜¯åˆ—åï¼‰ï¼Œä½¿ç”¨header=0ï¼Œå¦åˆ™ä½¿ç”¨header=None
        if any(c.isalpha() for c in first_line):
            df = pd.read_csv(file_path, delimiter=delimiter, encoding=encoding, header=0)
        else:
            df = pd.read_csv(file_path, delimiter=delimiter, encoding=encoding, 
                            header=None, comment='#')
        
        position_data = self._extract_positions_from_df(df)
        print(f"âœ… TXTæ ¼å¼åŠ è½½ä½ç½®æ•°æ®: {position_data.shape[0]}ç»„æ•°æ®")
        return position_data
    
    def _parse_excel_positions(self, file_path):
        """è§£æExcelæ ¼å¼ä½ç½®æ•°æ®"""
        if openpyxl is None:
            raise ImportError("éœ€è¦å®‰è£…openpyxlæ¥æ”¯æŒExcelæ ¼å¼")
        
        df = pd.read_excel(file_path, sheet_name=0)
        position_data = self._extract_positions_from_df(df)
        print(f"âœ… Excelæ ¼å¼åŠ è½½ä½ç½®æ•°æ®: {position_data.shape[0]}ç»„æ•°æ®")
        return position_data
    
    def _extract_positions_from_df(self, df):
        """ä»DataFrameæ™ºèƒ½æå–ä½ç½®æ•°æ®"""
        config = self.config.get('data_input', {}).get('positions', {})
        pos_patterns = config.get('position_patterns', ["X", "Y", "Z"])
        ori_patterns = config.get('orientation_patterns', ["Rx", "Ry", "Rz"])
        
        # æŸ¥æ‰¾ä½ç½®åˆ—
        pos_columns = []
        for pattern in pos_patterns:
            for df_col in df.columns:
                if pattern.lower() in str(df_col).lower():
                    pos_columns.append(df_col)
                    break
            if len(pos_columns) == 3:
                break
        
        # æŸ¥æ‰¾å§¿æ€åˆ—
        ori_columns = []
        for pattern in ori_patterns:
            for df_col in df.columns:
                if pattern.lower() in str(df_col).lower():
                    ori_columns.append(df_col)
                    break
            if len(ori_columns) == 3:
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…åˆ—ï¼Œä½¿ç”¨é»˜è®¤åˆ—
        if len(pos_columns) != 3 or len(ori_columns) != 3:
            if df.shape[1] >= 6:
                all_columns = df.columns[:6].tolist()
                pos_columns = all_columns[:3]
                ori_columns = all_columns[3:6]
            else:
                raise ValueError(f"ä½ç½®æ•°æ®åˆ—æ•°ä¸è¶³ï¼Œéœ€è¦è‡³å°‘6åˆ—ï¼Œå®é™…{df.shape[1]}åˆ—")
        
        # æå–æ•°æ®
        position_data = df[pos_columns + ori_columns].values.astype(float)
        
        if position_data.shape[1] != 6:
            raise ValueError(f"ä½ç½®æ•°æ®åˆ—æ•°é”™è¯¯ï¼ŒæœŸæœ›6åˆ—ï¼Œå®é™…{position_data.shape[1]}åˆ—")
        
        return position_data

# å…¨å±€è§£æå™¨å®ä¾‹
_smart_parser = None

def get_smart_parser():
    """è·å–æ™ºèƒ½è§£æå™¨å®ä¾‹"""
    global _smart_parser
    if _smart_parser is None:
        _smart_parser = SmartDataParser()
    return _smart_parser

def load_config(config_file=None):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    global _config
    
    # å¦‚æœå·²ç»åŠ è½½è¿‡é…ç½®ï¼Œç›´æ¥è¿”å›
    if _config is not None:
        return _config
        
    if config_file is None:
        config_file = DEFAULT_CONFIG_FILE
    
    # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    if not os.path.exists(config_file):
        print(f"è­¦å‘Š: é…ç½®æ–‡ä»¶ {config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        _config = get_default_config()
        return _config
    
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            _config = yaml.safe_load(f)
        print(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
        return _config
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        print("ä½¿ç”¨é»˜è®¤é…ç½®")
        _config = get_default_config()
        return _config

def get_default_config():
    """è·å–é»˜è®¤é…ç½®"""
    return {
        'data_files': {
            'joint_angle_raw': 'data/joint_angle.csv',
            'laser_pos_raw': 'data/laser_pos.csv', 
            'dh_params': 'data/dh.csv',
            'joint_limits': 'data/joint_limits.csv',
            'calibration_results': 'data/hand_eye_calibration.csv'
        },
        'robot_config': {
            'error_weights': [1.0, 1.0, 1.0, 0.01, 0.01, 0.01],
            'fixed_indices': []
        },
        'optimization': {
            'lm_optimization': {
                'alternate_optimization': {
                    'max_alt_iterations': 4,
                    'convergence_tol': 1e-4,
                    'max_sub_iterations_group1': 10,
                    'max_sub_iterations_group2': 10
                },
                'damping': {
                    'lambda_init_group1': 2.0,
                    'lambda_init_group2': 0.001,
                    'lambda_init_default': 0.01,
                    'lambda_max': 1e8,
                    'lambda_min': 1e-7,
                    'damping_type': 'marquardt'
                },
                'convergence': {
                    'parameter_tol': 1e-10,
                    'error_tol': 1e-12,
                    'max_inner_iterations': 10,
                    'rho_threshold': 0.0
                },
                'constraints': {
                    'max_theta_change_degrees': 1.0,
                    'enable_quaternion_normalization': True
                },
                'output': {
                    'save_delta_values': True,
                    'delta_csv_file': 'results/delta_values.csv',
                    'save_optimization_results': True,
                    'results_prefix': 'results/optimized'
                }
            }
        }
    }

def get_config():
    """è·å–å½“å‰é…ç½®"""
    global _config
    if _config is None:
        load_config()
    return _config

def get_file_path(key):
    """è·å–æ–‡ä»¶è·¯å¾„"""
    config = get_config()
    return config['data_files'].get(key, '')

def get_error_weights():
    """è·å–è¯¯å·®æƒé‡"""
    config = get_config()
    return np.array(config['robot_config']['error_weights'])

def get_fixed_indices():
    """è·å–å›ºå®šå‚æ•°ç´¢å¼•"""
    config = get_config()
    return config['robot_config']['fixed_indices']

def extract_joint_angles_from_raw(file_path=None):
    """æ™ºèƒ½æå–å…³èŠ‚è§’åº¦æ•°æ® - æ”¯æŒå¤šç§æ ¼å¼"""
    config = get_config()
    
    if file_path is None:
        file_path = config['data_files']['joint_angle_raw']
    
    try:
        # ä½¿ç”¨æ™ºèƒ½è§£æå™¨
        parser = get_smart_parser()
        result = parser.parse_joint_angles(file_path)
        return result
        
    except FileNotFoundError:
        print(f"é”™è¯¯: å…³èŠ‚è§’åº¦æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        raise
    except Exception as e:
        print(f"æå–å…³èŠ‚è§’åº¦æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise

def extract_laser_positions_from_raw(file_path=None):
    """æ™ºèƒ½æå–æ¿€å…‰ä½ç½®æ•°æ® - æ”¯æŒå¤šç§æ ¼å¼"""
    config = get_config()
    
    if file_path is None:
        file_path = config['data_files']['laser_pos_raw']
    
    try:
        # ä½¿ç”¨æ™ºèƒ½è§£æå™¨
        parser = get_smart_parser()
        result = parser.parse_positions(file_path)
        return result
        
    except FileNotFoundError:
        print(f"é”™è¯¯: æ¿€å…‰ä½ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        raise
    except Exception as e:
        print(f"æå–æ¿€å…‰ä½ç½®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise

def get_laser_tool_matrix():
    """æŠŠåŸå§‹æ¿€å…‰æ•°æ®è½¬æ¢ä¸º4*4çš„å˜æ¢çŸ©é˜µ"""
    laser_data = extract_laser_positions_from_raw()
    num_samples = laser_data.shape[0]
    laser_tool_matrix = np.zeros((num_samples, 4, 4))
    
    for i, data in enumerate(laser_data):
        x, y, z, rx, ry, rz = data
        
        # è®¡ç®—æ—‹è½¬çŸ©é˜µï¼ˆxyzå†…æ—‹ï¼‰
        R = Rotation.from_euler('xyz', [rx, ry, rz], degrees=True).as_matrix()
        
        # åˆ›å»ºå˜æ¢çŸ©é˜µ
        T = np.eye(4)
        T[0:3, 0:3] = R
        T[0:3, 3] = [x, y, z]
        
        laser_tool_matrix[i] = T
    return laser_tool_matrix

def load_dh_params():
    """åŠ è½½DHå‚æ•°ä»CSVæ–‡ä»¶"""
    config = get_config()
    file_path = config['data_files']['dh_params']
    
    dh_data = pd.read_csv(file_path, delimiter=',', skiprows=1, header=None).values
    
    if dh_data.shape[0] != 6 or dh_data.shape[1] != 4:
        raise ValueError(f"DHå‚æ•°æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šæœŸæœ›6è¡Œ4åˆ—ï¼Œå®é™…{dh_data.shape[0]}è¡Œ{dh_data.shape[1]}åˆ—")
    
    # å°†6x4çš„çŸ©é˜µå±•å¹³ä¸º24ä¸ªå‚æ•°çš„ä¸€ç»´æ•°ç»„
    dh_params_flat = dh_data.flatten()
    
    print(f"âœ… åŠ è½½DHå‚æ•°: {dh_params_flat.shape[0]}ä¸ªå‚æ•°")
    return dh_params_flat
        
def load_joint_limits():
    """åŠ è½½å…³èŠ‚é™ä½ä»CSVæ–‡ä»¶ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    global _joint_limits_cache
    
    # å¦‚æœå·²ç»ç¼“å­˜ï¼Œç›´æ¥è¿”å›
    if _joint_limits_cache is not None:
        return _joint_limits_cache
        
    config = get_config()
    file_path = config['data_files']['joint_limits']
    
    limits_data = pd.read_csv(file_path, delimiter=',', skiprows=1, header=None).values
    
    if limits_data.shape[0] != 6 or limits_data.shape[1] != 2:
        raise ValueError(f"å…³èŠ‚é™ä½æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼šæœŸæœ›6è¡Œ2åˆ—ï¼Œå®é™…{limits_data.shape[0]}è¡Œ{limits_data.shape[1]}åˆ—")
    
    # CSVæ ¼å¼æ˜¯ [UpperLimit, LowerLimit]ï¼Œéœ€è¦è½¬æ¢ä¸º [LowerLimit, UpperLimit]
    joint_limits = np.zeros((6, 2))
    joint_limits[:, 0] = limits_data[:, 1]  # LowerLimit (æœ€å°å€¼)
    joint_limits[:, 1] = limits_data[:, 0]  # UpperLimit (æœ€å¤§å€¼)
    
    # ç¼“å­˜ç»“æœ
    _joint_limits_cache = joint_limits
    print(f"âœ… åŠ è½½å…³èŠ‚é™ä½: {joint_limits.shape[0]}ä¸ªå…³èŠ‚")
    
    return joint_limits

def load_joint_angles():
    """åŠ è½½å…³èŠ‚è§’åº¦æ•°æ® - ç›´æ¥ä»åŸå§‹æ–‡ä»¶æå–"""
    return extract_joint_angles_from_raw()

def load_calibration_params():
    """åŠ è½½åˆå§‹åŸºåº§å’Œå·¥å…·åç§»å‚æ•°
    
    è¿”å›:
        tool_offset_params: TCPåç§»å‚æ•° (7ä¸ªå€¼ï¼šx,y,z,qx,qy,qz,qw) - æ•°å€¼è¾ƒå°
        laser_base_params: æ¿€å…‰åŸºåº§å‚æ•° (7ä¸ªå€¼ï¼šx,y,z,qx,qy,qz,qw) - æ•°å€¼è¾ƒå¤§
    """
    config = get_config()
    file_path = config['data_files']['calibration_results']
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        tool_offset_params = None
        laser_base_params = None
        
        for line in lines:
            line = line.strip()
            if line.startswith('base:'):
                # âš ï¸ baseå‚æ•° = æ¿€å…‰åŸºåº§å˜æ¢ (Laser -> Base) - æ•°å€¼è¾ƒå¤§ï¼Œé€šå¸¸æ•°ç™¾åˆ°æ•°åƒ
                param_str = line.split(':', 1)[1].strip()
                laser_base_params = np.array(ast.literal_eval(param_str))
            elif line.startswith('tool:'):
                # âš ï¸ toolå‚æ•° = TCPåç§» (Flange -> Tool) - æ•°å€¼è¾ƒå°ï¼Œé€šå¸¸å‡ æ¯«ç±³åˆ°å‡ åæ¯«ç±³  
                param_str = line.split(':', 1)[1].strip()
                tool_offset_params = np.array(ast.literal_eval(param_str))
        
        if tool_offset_params is None or laser_base_params is None:
            raise ValueError("æœªèƒ½ä»æ–‡ä»¶ä¸­è¯»å–å®Œæ•´çš„æ ¡å‡†å‚æ•°")
        
        # æ•°å€¼èŒƒå›´æ£€æŸ¥ï¼Œå¸®åŠ©å‘ç°å‚æ•°æ ‡ç­¾é”™è¯¯
        tool_pos_magnitude = np.linalg.norm(tool_offset_params[:3])
        base_pos_magnitude = np.linalg.norm(laser_base_params[:3]) 
        
        if tool_pos_magnitude > 1000:  # TCPåç§»è¶…è¿‡1ç±³ï¼Œå¯èƒ½æœ‰é—®é¢˜
            print(f"âš ï¸ è­¦å‘Š: TCPåç§»å‚æ•°æ•°å€¼å¼‚å¸¸å¤§ ({tool_pos_magnitude:.1f}), è¯·æ£€æŸ¥æ˜¯å¦ä¸baseå‚æ•°æ ‡ç­¾æå")
        if base_pos_magnitude < 100:   # æ¿€å…‰åŸºåº§è·ç¦»å°äº10cmï¼Œå¯èƒ½æœ‰é—®é¢˜  
            print(f"âš ï¸ è­¦å‘Š: æ¿€å…‰åŸºåº§å‚æ•°æ•°å€¼å¼‚å¸¸å° ({base_pos_magnitude:.1f}), è¯·æ£€æŸ¥æ˜¯å¦ä¸toolå‚æ•°æ ‡ç­¾æå")
            
        print(f"âœ… åŠ è½½æ ¡å‡†å‚æ•°: TCP + æ¿€å…‰åŸºåº§å˜æ¢")
        return tool_offset_params, laser_base_params
        
    except Exception as e:
        print(f"è¯»å–æ ¡å‡†ç»“æœæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        raise

def get_initial_params():
    """è·å–åˆå§‹å‚æ•°(38ä¸ªå‚æ•°)"""
    tool_offset_params, laser_base_params = load_calibration_params()
    dh_params = load_dh_params()  
    initial_params = np.concatenate((
        dh_params,  
        tool_offset_params,
        laser_base_params
    ))
    return initial_params

def get_parameter_groups(exclude_fixed=True):
    """è·å–å‚æ•°ç»„"""
    all_indices_group1 = list(range(0, 34))
    all_indices_group2 = list(range(34, 38))
    
    fixed_indices = get_fixed_indices()
    
    if exclude_fixed:
        # æ’é™¤å›ºå®šå‚æ•°
        group1_indices = [idx for idx in all_indices_group1 if idx not in fixed_indices]
        group2_indices = [idx for idx in all_indices_group2 if idx not in fixed_indices]
        return group1_indices, group2_indices
    else:
        return all_indices_group1, all_indices_group2

def get_optimizable_indices():
    """è·å–å¯ä¼˜åŒ–å‚æ•°ç´¢å¼•"""
    fixed_indices = get_fixed_indices()
    return [i for i in range(38) if i not in fixed_indices]

#! LMä¼˜åŒ–é…ç½®è¯»å–å‡½æ•°

def get_lm_config():
    """è·å–LMä¼˜åŒ–å®Œæ•´é…ç½®"""
    config = get_config()
    return config.get('optimization', {}).get('lm_optimization', {})

def get_alternate_optimization_config():
    """è·å–äº¤æ›¿ä¼˜åŒ–é…ç½®"""
    lm_config = get_lm_config()
    config = lm_config.get('alternate_optimization', {
        'max_alt_iterations': 4,
        'convergence_tol': 1e-4,
        'max_sub_iterations_group1': 10,
        'max_sub_iterations_group2': 10
    })
    
    # ç¡®ä¿æ•°å€¼å‚æ•°æ˜¯æ­£ç¡®çš„ç±»å‹
    if 'convergence_tol' in config:
        config['convergence_tol'] = float(config['convergence_tol'])
    if 'max_alt_iterations' in config:
        config['max_alt_iterations'] = int(config['max_alt_iterations'])
    if 'max_sub_iterations_group1' in config:
        config['max_sub_iterations_group1'] = int(config['max_sub_iterations_group1'])
    if 'max_sub_iterations_group2' in config:
        config['max_sub_iterations_group2'] = int(config['max_sub_iterations_group2'])
    
    return config

def get_damping_config():
    """è·å–é˜»å°¼å‚æ•°é…ç½®"""
    lm_config = get_lm_config()
    config = lm_config.get('damping', {
        'lambda_init_group1': 2.0,
        'lambda_init_group2': 0.001,
        'lambda_init_default': 0.01,
        'lambda_max': 1e8,
        'lambda_min': 1e-7,
        'damping_type': 'marquardt'
    })
    
    # ç¡®ä¿æ•°å€¼å‚æ•°æ˜¯æµ®ç‚¹æ•°ç±»å‹
    for key in ['lambda_init_group1', 'lambda_init_group2', 'lambda_init_default', 
                'lambda_max', 'lambda_min']:
        if key in config:
            config[key] = float(config[key])
    
    return config

def get_convergence_config():
    """è·å–æ”¶æ•›æ§åˆ¶é…ç½®"""
    lm_config = get_lm_config()
    config = lm_config.get('convergence', {
        'parameter_tol': 1e-10,
        'error_tol': 1e-12,
        'max_inner_iterations': 10,
        'rho_threshold': 0.0
    })
    
    # ç¡®ä¿æ•°å€¼å‚æ•°æ˜¯æ­£ç¡®ç±»å‹
    for key in ['parameter_tol', 'error_tol', 'rho_threshold']:
        if key in config:
            config[key] = float(config[key])
    if 'max_inner_iterations' in config:
        config['max_inner_iterations'] = int(config['max_inner_iterations'])
    
    return config

def get_constraints_config():
    """è·å–å‚æ•°çº¦æŸé…ç½®"""
    lm_config = get_lm_config()
    config = lm_config.get('constraints', {
        'max_theta_change_degrees': 1.0,
        'enable_quaternion_normalization': True
    })
    
    # ç¡®ä¿æ•°å€¼å‚æ•°æ˜¯æµ®ç‚¹æ•°ç±»å‹
    if 'max_theta_change_degrees' in config:
        config['max_theta_change_degrees'] = float(config['max_theta_change_degrees'])
    if 'enable_quaternion_normalization' in config:
        config['enable_quaternion_normalization'] = bool(config['enable_quaternion_normalization'])
    
    return config

def get_output_config():
    """è·å–è¾“å‡ºè®¾ç½®é…ç½®"""
    lm_config = get_lm_config()
    return lm_config.get('output', {
        'save_delta_values': True,
        'delta_csv_file': 'results/delta_values.csv',
        'save_optimization_results': True,
        'results_prefix': 'results/optimized'
    })

def get_max_theta_change_radians():
    """è·å–thetaå‚æ•°æœ€å¤§å˜åŒ–é‡ï¼ˆå¼§åº¦ï¼‰"""
    constraints_config = get_constraints_config()
    max_theta_degrees = constraints_config.get('max_theta_change_degrees', 1.0)
    return np.deg2rad(max_theta_degrees)

def clear_cache():
    """æ¸…ç†æ‰€æœ‰ç¼“å­˜ï¼Œç¡®ä¿é‡æ–°åŠ è½½"""
    global _config, _joint_limits_cache
    _config = None
    _joint_limits_cache = None
    print("ğŸ§¹ å·²æ¸…ç†æ‰€æœ‰ç¼“å­˜")

